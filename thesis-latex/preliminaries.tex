\section{Answer Set Programming}

When speaking of \gls{asp}, we nowadays mostly refer to the language specfied by the ASP-Core2 standard~\cite{asp-core2}. It uses the \emph{stable model semantics} by Gelfond and Lifschitz~\cite{stable-models} as a formal basis and enhances it with support for advanced concepts such as disjunctive programs, aggregate literals and weak constraints. This chapter describes the input language supported by the Alpha solver, which will serve as the basis on which we will define the Evolog language.

\subsection{Syntax}
\label{subsec:prelims-asp-syntax}

\begin{definition}[Integer numeral]
\label{def:prelims-asp-syntax-int}
An \emph{integer numeral} in the context of an \gls{asp} program is a string matching the regular expression:
\begin{lstlisting}[style=code]
(-)?[0-9]+
\end{lstlisting}
The set of all valid integer numerals is denoted as $\INTs$.
\end{definition}

\begin{definition}[Identifier]
\label{def:prelims-asp-syntax-id}
An \emph{identifier} in the context of an \gls{asp} program is a string matching the regular expression:
\begin{lstlisting}[style=code]
[a-z][a-zA-Z0-9\_]*
\end{lstlisting}
The set of all valid identifiers is denoted as $\IDs$.
\end{definition}

\begin{definition}[Variable Name]
\label{def:prelims-asp-syntax-var}
A \emph{variable name} in the context of an \gls{asp} program is a string matching the regular expression:
\begin{lstlisting}[style=code]
[A-Z][a-zA-Z0-9\_]*
\end{lstlisting}
The set of all valid variable names is denoted as $\VARs$.
\end{definition}

\begin{definition}[Term]
\label{def:prelims-asp-syntax-term}
A \emph{term} is inductively defined as follows:
\begin{itemize}
	\item Any \emph{constant} $c \in (\INTs \cup \IDs)$ is a term.
	\item Any \emph{variable} $v \in \VARs$ is a term.
	\item Given terms $t_1, t_2$, any \emph{artihmetic expression} $t_1 \oplus t_2$ with $\oplus \in \{+, - , *, /, **\}$ is a term.
	\item Given terms $t_1, t_2$, any \emph{interval expression} $t_1 \ldots t_2$ is a term.
	\item For function symbol $f \in \IDs$ and argument terms $t_1, \ldots, t_n$, the \emph{functional expression} $f(t_1, \ldots, t_n)$ is a term.
\end{itemize}
\end{definition}

\begin{definition}[Subterms]
\label{def:prelims-asp-syntax-subterms}
Given a term $t$, the set of \emph{subterms} of $t$, $st(t)$, is defined as follows:
\begin{itemize}
	\item If $t$ is a \emph{constant} or \emph{variable}, $st(t) = \{t\}$.
	\item If $t$ is an \emph{arithmetic expression} $t_1 \oplus t_2$, $st(t) = st(t_1) \cup st(t_2)$.
	\item If $t$ is an \emph{interval expression} $t_1 \ldots t_2$, $st(t) = st(t_1) \cup st(t_2)$.
	\item If $t$ is a \emph{functional expression} with argument terms $t_1, \ldots, t_n$, $st(t) = st(t_1) \cup \ldots \cup st(t_n)$.
\end{itemize}
A term is called \emph{ground} if it is variable-free, i.e. none of its subterms is a variable.
\end{definition}

\begin{definition}[Basic Atom]
\label{def:prelims-asp-syntax-atom}
Given a predicate symbol $p \in \IDs$ and argument terms $t_1,\ldots,t_n$, the expression
\[
	p(t_1,\ldots,t_n)
\]
is called a \emph{atom}. An atom is ground if all of its argument terms are ground. A ground atom with predicate $p$ is called an \emph{instance} of $p$.
\end{definition}

\begin{definition}[Comparison Atom]
\label{def:prelims-asp-syntax-cmp-atom}
Given terms $t_1$ and $t_2$ and comparison operator $\odot$ where $\odot \in \{ <, \leq, =, \geq, >, \neq \}$, the expression
\[
	t_1 \odot t_2
\]
is called a \emph{comparison atom}. Syntactically, a comparison atom is a regular atom where the predicate symbol (i.e. comparison operator) is written in infix- rather than prefix-notation.
\end{definition}

\begin{definition}[External Atom]
\label{def:prelims-asp-syntax-ext-atom}
Given an \emph{external predicate name} $\mathit{ext}$, \emph{input terms} $t_1,\ldots,t_n$ and \emph{output terms} $t_{n+1},\ldots,t_m$, the expression
\[
	\&\mathit{ext}[t_1,\ldots,t_n](t_{n+1},\ldots,t_m)
\]
is called an \emph{external atom}. Syntacticaly, external atoms are regular atoms where $\&\mathit{ext}$ is the predicate symbol and $t_1,\ldots,t_m$ are argument terms.
\end{definition}

\begin{definition}[Literal]
\label{def:prelims-asp-syntax-literal}
A literal in \gls{asp} is an atom $a$ or ("default"-)negated atom $\NOT\ a$. Literals wrapping comparison- or external atoms are called \emph{fixed interpretation literals}. Given a literal $l$, the expression $pred(l)$ refers to the predicate of $l$ (e.g $pred(p(a)) = p/1$).
\end{definition}

\begin{definition}[Rule, Program]
\label{def:prelims-asp-syntax-rule}
A \emph{rule} is an expression of form
\[
	a_H \leftarrow b_1,\ldots,b_n.
\]
for $n \geq 0$, where the \emph{rule head} $a_H$ is an atom and the \emph{rule body} $b_1,\ldots,b_n$ is a set of literals. An \gls{asp} \emph{program} is a set of rules. A rule with an empty body is called a \emph{fact}. A rule is \emph{ground} if both its head atom and all of its body literals are ground. By the same reasoning, a program is ground if all of its rules are ground.\\
Given a rule $r$, we refer to the head of $r$ as $h(r)$ and the body of $r$ as $b(r)$. Furthermore, $b^+(r)$ is used to reference the set of \emph{positive body literals} of $r$, while $b^-(r)$ references the \emph{negative body literals}. 
\end{definition}

\begin{definition}[Constraint]
\label{def:prelims-asp-syntax-constraint}
A \emph{constraint} is a special form of rule, written as a rule with an empty head, i.e.
\[
	\leftarrow b_1,\ldots,b_n.
\]
It is syntactic sugar for
\[
	q \leftarrow b_1,\ldots,b_n, \NOT\ q.
\]
where $q$ is a propositional constant not occurring in any other rule in the program.
\end{definition}

\subsection{Semantics}
\label{subsec:prelims-asp-semantics}

\begin{definition}[Herbrand Universe]
\label{def:prelims-asp-semantics-hu}
The Herbrand Universe $HU_P$ of a Program $P$ is the set of all ground terms that can be constructed with respect to Definitions~\ref{def:prelims-asp-syntax-int},~\ref{def:prelims-asp-syntax-id} and \ref{def:prelims-asp-syntax-term}.
Note that most papers use stricter definitions of the Herbrand Universe where $HU_P$ consists only of terms constructible from constants occurring in $P$. The broader definition used here is chosen for ease of definition with respect to some of the extensions introduced in Section~\ref{sec:evolog-actions}.
\end{definition}

\begin{definition}[Herbrand Base]
\label{def:prelims-asp-semantics-hb}
The Herbrand Base $HB_P$ of a Program $P$ is the set of all ground atoms that can be constructed from the Herbrand Universe $HU_P$ according to definition~\ref{def:prelims-asp-syntax-atom}. 
\end{definition}

\begin{definition}[Herbrand Interpretation]
\label{def:prelims-asp-semantics-herbrand-interpretation}
A Herbrand Interpretation is a special form of first order interpretation where the domain of the interpretation is a Herbrand Universe and the interpretation of a term is the term itself, i.e. the corresponding element of $HU_P$. Intuitively, Herbrand Interpretations constitute listings of atoms that are true in a given program. Since the domain of a Herbrand Interpretation is always the Herbrand Universe $HU_P$, we only need to give a predicate interpretation for the predicates occurring in a program $P$ in oder to fully specify a Herbrand Interpretation. We can therefore denote Herbrand Interpretations as sets of atoms $I \subseteq HB_P$.
\end{definition}

\subsubsection{Grounding}
\label{subsubsec:prelims-grounding}
Given a program $P$ containing variables, \emph{grounding} refers to the process of converting $P$ into a semantically equivalent propositional, i.e. variable-free, program.

\begin{definition}[Substitution, adapted from~\cite{lazy-cdnl}]
\label{def:prelims-asp-semantics-substitution}
A substitution $\sigma: \VARs \mapsto (\IDs \cup \INTs)$ is a mapping from variables to constants. For a atom $a$, applying a a substitution results in a substituted atom $a\sigma$ in which variables are replaced according to $\sigma$. Substitutions are applied to rules  by applying them to every individual atom or literal within the rule. By the same mechanism, we can apply substitutions to programs by applying the to all rules.
\end{definition}

\begin{definition}[Grounding]
\label{def:prelims-asp-semantics-grounding}
Given a rule $r$, the \emph{grounding} of $r$, $\mathit{grnd}(r)$, is a set of substitutions $S$, such that the set of ground rules resulting from applying the substitutions in $S$ is semantically equivalent to $r$. In a slight abuse of terminology, \emph{grounding} in this work also refers to the set of ground rules resulting from applying $S$ as well as the process of finding said set.
\end{definition}

\subsubsection{Stable Model Semantics}
\label{subsubsec:prelims-asp-semantics-stable-models}

\begin{definition}[Fixed interpretation literals]
\label{def:prelims-asp-semantics-fixedinterpretation-literals}	
Fixed interpretation literals, i.e. comparison- and external literals, respectively, are interpreted by means of a program-independent oracle function $f_O : H_{U}(P)^{*} \mapsto \{ \top, \bot \}$, i.e. a fixed interpretation literal with argument terms $t_1,\ldots,t_n$ has the same truth value under all interpretations.
\end{definition}

\begin{definition}[Truth of Atoms and Literals]
\label{def:prelims-asp-semantics-truth}
A positive ground literal $l$ with atom $a$ is true w.r.t. a Herbrand Interpretation $I$, i.e. $I \models l$ if
\begin{itemize}
	\item $a$ is a basic atom contained in $I$, i.e. $a \in I$,
	\item $a$ is a fixed interpretation literal with terms $t_1,\ldots,t_n$ and $f_O(t_1,\ldots,t_n) = \top$.
\end{itemize} 
For a negative ground literal $\NOT\ a$, the reverse holds, i.e. $I \models \NOT\ a$ if
\begin{itemize}
	\item $a$ is a basic atom not contained in $I$, i.e. $a \notin I$,
	\item $a$ is a fixed interpretation literal with terms $t_1,\ldots,t_n$ and $f_O(t_1,\ldots,t_n) = \bot$.
\end{itemize} 
A set of literals $L$ is true w.r.t. an interpretation $I$ if $I \models l$ holds for every literal $l \in L$. 
\end{definition}

\begin{definition}[Positive Logic Program]
\label{def:prelims-asp-semantics-positive-program}
A \emph{positive} logic program is a program according to Definition \ref{def:prelims-asp-syntax-rule}, where all rule bodies are positive, i.e. no rule body contains a negated atom.
\end{definition}

\begin{definition}[Immediate Consequence Operator, adapted from~\cite{asp-primer}]
\label{def:prelims-asp-semantics-immediate-consequence}
Given a Herbrand Interpretation $I$ and a ground positive logic program $P$, the immediate  consequence operator $T_P(I)$ defines a monotonic function $T_P: 2^{HB_P} \mapsto 2^{HB_P}$ such that
\[
	T_P(I) = \{h(r)\ |\ r \in P \land I \models b(r)\}
\]
i.e. the result set of applying $T_P$ with a Herbrand Interpretation $I$ contains the heads of all rules whose body is true under $I$.
\end{definition}

\begin{definition}[Least Model of positive logic programs]
\label{def:prelims-asp-semantics-least-model}
The least model $LM(P)$ of a (ground) positive logic program $P$ is the least fixpoint of the $T_P$ operator  of $P$, i.e. the set toward which the sequence $\langle T^{i}_{P} \rangle$, with $i \geq 0$, $T^{0}_P = \emptyset$ and $T^{i}_P = T_P(T^{i-1}_P)$ for $i \geq 1$, converges. The existence of said fixpoint and its characterisation as limit of $\langle T^{i}_{P} \rangle$ follow from the fixpoint theorems of Knaster, Tarski and Kleene, respectively.
\end{definition}

\begin{definition}[Gelfond-Lifschitz Reduct, adapted from~\cite{stable-models} and~\cite{asp-primer}]
\label{def:prelims-asp-semantics-gl-reduct}
Given a ground \gls{asp} program $P$ and a Herbrand Interpretation $I$, the \emph{Gelfond-Lifschitz-Reduct} ("GL-reduct") $P^{I}$ of $P$ with respect to $I$ is the program obtained by:
\begin{itemize}
	\item removing from $P$ all rules $r$ that are "blocked", i.e. $I \not\models l$ for some literal $l \in b^{-}(r)$ 
	\item and removing the negative body of all other rules.
\end{itemize}
Note that $P^{I}$ is a positive logic program.
\end{definition}

\begin{definition}[Answer Set~\cite{stable-models}~\cite{asp-primer}]
\label{def:prelims-asp-semantics-answer-set}
A Herbrand Interpretation $I$ of an \gls{asp} program $P$ is an \emph{answer set} or \emph{stable model} of $P$ iff it is the least model $LM(P^I)$ of the GL-reduct $P^I$ of $P$. We denote the set of Answer Sets of a program $P$ as $\mathit{AS}(P)$.
\end{definition}

\section{Lazy-grounding answer-set solving using Alpha}

The theoretical notion underlying lazy-grounding answer-set solving is that of a \emph{Computation Sequence}, which is formalized in Definition~\ref{def:prelims-asp-semantics-compseq}. Intuitively, a computation sequence is a sequence of (ground) rules firing, such that, at the end, the atoms derived by the rules from the computation sequence (together with all facts of the program) constitute an answer set.

\begin{definition}[Computation Sequence, adapted from~\cite{lazy-cdnl} and~\cite{asperix-fw-chain}]
\label{def:prelims-asp-semantics-compseq}
Let $P$ be an \gls{asp} program and $S = (A_0,\ldots,A_{\infty})$ a sequence of assignments, i.e. herbrand interpretations denoted by a set of atoms assumed to be true, then $S$ is called a \emph{computation sequence} iff
\begin{itemize}
	\item $A_0 = \emptyset$
	\item $\forall i \geq 1: A_i \subseteq T_P(A_{i - 1})$, i.e. every $A_i$ is a consequence of its predecessor in the sequence,
	\item $\forall i \geq 1: A_{i - 1} \subseteq A_{i}$, i.e. S is monotonic,
	\item $A_{\infty} = \cup^{\infty}_{i = 0} A_i = T_P(A_{\infty})$, i.e. $S$ converges toward a fixpoint and
	\item $\forall i \geq 1: \forall a \ \in A_i \setminus A_{i - 1}, \exists r \in P: h(r) = a \land \forall j \geq i - 1: A_j \models a$, i.e. applicability of rules is persistent.
\end{itemize}
$A_{\infty}$ is an answer set of $P$ iff $S$ is a computation sequence. Note that there may exist an arbitrary number of computation sequences leading to the same answer set.
\end{definition}

It is easily observed that, in order to calculate computation sequences, one does not need a full grounding of the input program. Since facts are ground by definition, rules that only depend on facts can be grounded (and evaluated) based on facts alone. The same holds for rules depending on facts and rules from the previous step, etc. Example~\ref{ex:compseq-naive-calc} demonstrates how a computation sequence for a very simple positive program can be caluclated using a naive algorithm based on repeated application of the $T_P$-operator.

\begin{example}[Lazy-grounding a positive logic program]
\label{ex:compseq-naive-calc}
In order to illustrate the use of computation sequences for lazy-grounding, we consider the program $P$ in Listing~\ref{lst:compseq-naive-calc}. We denote the rule on line 2 as $r_1$ and the one on line 3 as $r_2$.
\begin{lstlisting}[style=asp-code, label={lst:compseq-naive-calc}, caption={A positive, non-ground program}]
p(a). p(b). p(c). q(b). q(c). q(d).
r(X) :- p(X), q(X).
t(X, Y) :- r(X), r(Y), X != Y.	
\end{lstlisting}
Starting from the set of facts on line 1, which we denote as $F$, we now look for rules that only depend on predicates in $F$ (i.e. body literals only have predicates for which we already know ground instances). The only applicable rule is $r_1$ for which we  can construct ground instances \texttt{r(b) :- p(b), q(b)} and \texttt{r(c) :- p(c), q(c)}. Continuing this process, now based on the set $F \cup \{r(b),r(c)\}$, we find ground instances \texttt{t(b, c) :- r(b), r(c), b != c} and \texttt{t(c, b) :- r(c), r(b), c != b} of $r_2$. We thus arrive at the following computation sequence:
\begin{align*}
	A_0 &= \{p(a), p(b), p(c), q(b), q(c), q(d)\},\\
	A_1 &= \{p(a), p(b), p(c), q(b), q(c), q(d), r(b), r(c)\},\\
	A_2 &= \{p(a), p(b), p(c), q(b), q(c), q(d), r(b), r(c), t(b, c), t(c, b)\}\\
\end{align*}	
The last element of the sequence, $A_2$ is the sole answer set of $P$.
\end{example}	

While the intuitive approach from Example~\ref{ex:compseq-naive-calc} clearly works for positive programs, things get more complicated when negation is involved. Consider the following program:
\begin{lstlisting}[style=asp-code]
	p(a). p(b). p(c). q(c).
	s(X) :- p(X), q(X).
	t(X) :- p(X), not s(X).
\end{lstlisting}
In order to arrive a the correct answer set $A = \{p(a), p(b), p(c), q(c), s(c), t(a), t(b)\}$, one has to first evaluate all rules that could potentially derive instances of $s/1$, before starting to evaluate the last rule, in order to end up with a valid computation sequence. Evaluation orders for this kind of programs can be calculated using the notion of \emph{stratification}~\cite{stratification} which is described in detail in Section~\ref{subsec:stratified-evaluation}.

\subsection{Structural Dependency Analysis and Stratified Evaluation}
\label{subsec:stratified-evaluation}

In a nutshell, a \emph{stratifiable} logic program is a program, for which we can calculate a partition into sub-programs, such that, when evaluating the sub-programs sequentially, one always ends up with a correct computation sequence. Definition~\ref{def:prelims-asp-semantics-stratification} formally characterizes stratifiable programs.

\begin{definition}[Stratifiable answer set program, as stated in~\cite{partial-eval}, adapted from\cite{stratification},~\cite{asp-primer}]
\label{def:prelims-asp-semantics-stratification}	
Given a program $P = \{r_{0}, ..., r_{n}\}$, $P$ is called \emph{stratifiable} iff there is a partition $P = P_{S_0} \cup\ ... \cup\ P_{S_n}$ so that for each $0 \le i \leq n$ the following holds:
\begin{itemize}
	\item For every positive body literal $l_{b}$ of every rule in $P_{S_i}$, every rule that derives instances of the predicate $\mathit{pred}(l_{b})$, i.e. where the predicate of the head atom $\mathit{pred}(a_H)$ is $\mathit{pred}(l_{b})$, is contained in some $P_{S_j}$ with $j \leq i$.
	\item For every negative body literal $\mathit{not}\ l_{b}$ of every rule in $P_{S_i}$, every rule that derivesinstances of the predicate $\mathit{pred}(l_{b})$, i.e. where the predicate of the head atom $\mathit{pred}(a_H)$is $\mathit{pred}(l_{b})$, is contained in some $P_{j}$ with $j < i$.
\end{itemize}
The individual subprograms $P_{S_i}$ are called strata. A \emph{stratification} $S = \{P_{S_0},\ldots, P_{S_n}\}$refers to the set of all strata making up a partition which satisfies the criteria above.
\end{definition}

The least model, i.e. the sole answer set, of a stratifiable program can be computed by sequentially applying the immediate consequence operator to every stratum, see Definition~\ref{def:prelims-asp-semantics-stratified-compseq}.

\begin{definition}[Least model of stratifiable programs, adapted from~\cite{asp-primer}]
\label{def:prelims-asp-semantics-stratified-compseq}
Let $P_{strat}$ be a stratifiable program for which a stratification $S = \{P_{S_0},\ldots,P_{S_n}\}$ exists and let $T_{P_{S_i}}$ be the immediate consequence operator for the sub-program defined by stratum $P_{S_i}$. Furthermore, for a model $M$, let $pr(M)$ be the program consisting of the facts representing the atoms in $M$.
Then the least model $LM(P_{strat})$ of $P_{strat}$ is defined as follows.
The sequence $\langle M_{S_i} \rangle,\ 0 \leq i \leq n$ with $M_{S_0} = \mathit{lfp}(T_{P_{S_0}})$ and $M_{S_i} = \mathit{lfp}(T_{(P_{S_{i}} \cup\ pr(M_{S_{i-1}}))})$ for all $1 \leq i \leq n$ defines the (iterative) least model for each stratum. The least model $LM(P_{strat})$ of program $P_{strat}$ is then the iterative least model of the highest stratum $M_{S_n}$, i.e. the end of the sequence $\langle M_{S_i} \rangle$.
\end{definition}

Since the evaluation mode described in Definition~\ref{def:prelims-asp-semantics-stratified-compseq} does not require any backtracking, i.e. the result of each step is part of the final result, we observe that te intermediate results of the immediate consequence operator yield a computation sequence for $P$. Example~\ref{ex:prelims-strat-eval} illustrates evaluation of a short stratifiable program.

\begin{example}[Evaluating a stratified program]
\label{ex:prelims-strat-eval}	
Consider the program $P$ from Listing~\ref{lst:prelims-strat-eval}.
\begin{lstlisting}[style=asp-code, label={lst:prelims-strat-eval}, caption={A stratifiable program.}]
p(a). p(b). p(c). q(c). q(d).

s(X) :- p(X), q(X).
t(X) :- p(X), not s(X).
u(X) :- q(X), not p(X).

v(X, Y) :- t(X), u(Y), X != Y.
\end{lstlisting}
A possible stratification $S$ of $P$ could look as follows:
\begin{align*}
	S_0 = \{&p(a).~p(b).~p(c).~q(c).~q(d). \\
			&s(X)~\leftarrow~p(X),~q(X).\} \\
	S_1 = \{&t(X)~\leftarrow~p(X),~not~s(X). \\
			&u(X)~\leftarrow~q(X),~not~p(X).\} \\
	S_2 = \{&v(X, Y)~\leftarrow~t(X),~u(Y),~X~!=~Y.\}
\end{align*}
In this case, the least model of $P$ can be calculated using the method from Definition~\ref{def:prelims-asp-semantics-stratified-compseq}. The individual results of the $T_P$ operator constitute a computation sequence.
\begin{align*}
	T_{P_{S_0}}^1 &= T_{P_{S_0}}(\emptyset) = \{p(a), p(b), p(c), q(c), q(d)\} \\
	T_{P_{S_0}}^2 &= T_{P_{S_0}}(T_{P_{S_0}}^1) = \{p(a), p(b), p(c), q(c), q(d), s(c)\} \\
	T_{P_{S_0}}^3 &= T_{P_{S_0}}(T_{P_{S_0}}^2) = \{p(a), p(b), p(c), q(c), q(d), s(c)\} = lfp(T_{P_{S_0}})\\
	\\
	T_{P_{E1}} &= T_{P_{S_1\cup pr(lfp(T_{P_{S_0}}))}}\\
	T_{P_{E1}}^1 &= T_{P_{E1}}(\emptyset) = \{p(a), p(b), p(c), q(c), q(d), s(c)\} \\
	T_{P_{E1}}^2 &= T_{P_{E1}}(T_{P_{E1}}^1) = \{p(a), p(b), p(c), q(c), q(d), s(c), t(a), t(b), u(d)\} \\
	T_{P_{E1}}^3 &= T_{P_{E1}}(T_{P_{E1}}^2) = \{p(a), p(b), p(c), q(c), q(d), s(c), t(a), t(b), u(d)\} = lfp(T_{P_{E1}}) \\
	\\
	T_{P_{E2}} &= T_{P_{S_2\cup pr(lfp(T_{P_{E1}}))}}\\
	T_{P_{E2}}^1 &= T_{P_{E2}}(\emptyset) = \{p(a), p(b), p(c), q(c), q(d), s(c), t(a), t(b), u(d)\} \\
	T_{P_{E2}}^2 &= T_{P_{E2}}(T_{P_{E2}}^1) = \{p(a), p(b), p(c), q(c), q(d), s(c), t(a), t(b), u(d), v(a, d), v(b, d)\} \\
	T_{P_{E2}}^3 &= T_{P_{E2}}(T_{P_{E2}}^2) = \{p(a), p(b), p(c), q(c), q(d), s(c), t(a), t(b), u(d), v(a, d), v(b, d)\} = lfp(T_{P_{E2}})\\
	\\
	LM(P) &= lfp(T_{P_{E2}})
\end{align*}	
\end{example}	

However, in general, ASP programs are not stratifiable. Example~\ref{ex:prelims-nonstrat} shows a typical non-stratifiable program.

\begin{example}[A non-stratifiable program]
\label{ex:prelims-nonstrat}
Consider a variant of the well-known 3-coloring problem for undirected graphs, where some vertices "stay blank", i.e. they are excluded from coloring. Essentially, prior to calculating actual colorings, we remove all ignored vertices and their corresponding edges from the graph and color only the resulting subgraph. Program $P_{col}$ in Listing~\ref{lst:prelims-3col-var} shows a possible encoding of this problem.
\begin{lstlisting}[style=asp-code, label={lst:prelims-3col-var}, caption={Graph 3-coloring with excluded vertices}]
vertex(a). vertex(b). vertex(c). vertex(d).
edge(a, b). edge(a, c). edge(a, d).
edge(b, c). edge(b, d). edge(c, d).
edge(X, Y) :- edge(Y, X).

exclude_vertex(d).
exclude_edge(V1, V2) :- edge(V1, V2), exclude_vertex(V1).
exclude_edge(V1, V2) :- exclude_edge(V2, V1).

coloring_vertex(V) :- vertex(V), not exclude_vertex(V).
coloring_edge(V1, V2) :- 
	edge(V1, V2), not exclude_edge(V1, V2).

% Guess colors
red(V) :- coloring_vertex(V), not green(V), not blue(V).
green(V) :- coloring_vertex(V), not red(V), not blue(V).
blue(V) :- coloring_vertex(V), not red(V), not green(V).

% Filter invalid guesses
:- coloring_vertex(V1), coloring_vertex(V2), 
	coloring_edge(V1, V2), red(V1), red(V2).
:- coloring_vertex(V1), coloring_vertex(V2), 
	coloring_edge(V1, V2), green(V1), green(V2).
:- coloring_vertex(V1), coloring_vertex(V2), 
	coloring_edge(V1, V2), blue(V1), blue(V2).
\end{lstlisting}
Clearly, $P_{col}$ is not stratifiable - the color assignment rules cyclically depend on each other through negated body literals. In other words, the rules on lines 15 to 17 are \emph{mutually exclusive}, i.e. a solver has to \emph{choose} which of the three should fire for a given ground instance of $coloring\_vertex/1$.
\end{example}

The program from Example~\ref{ex:prelims-nonstrat} can not be evaluated by iterative fixpoint-calculation as in Example~\ref{ex:prelims-strat-eval} because it is not stratifiable. However, it is still possible to evaluate at least a part of it using this method, rather than a computationally more complex "trial-and-error"-approach. This partial evaluation approach uses \emph{splitting sets}, which are characterized in Definition~\ref{def:prelims-asp-semantics-splitting-set}. Intuitively, a splitting set $S$ is a set of atoms, such that if an atom $a$ is in $S$, also all atoms it depends on (i.e. body atoms of rules deriving $a$) are in $S$. By the splitting set theorem, a splitting sets lets us partition a program $P$ such that it can be evaluated incrementally, by first evaluating the bottom $B_U(P)$ and then the top $T_U(P)$. Since this section deals with non-ground programs specifically, we also give an adapted definition for splitting sets of nonground programs, see Definition~\ref{def:prelims-asp-semantics-nonground-splitting-set}. Example~\ref{ex:prelims-nonstrat-splitting-sets} applies the splitting set theorem to the program from Example~\ref{ex:prelims-nonstrat}.

\begin{definition}[Splitting Set, adapted from~\cite{splitting-sets}]
\label{def:prelims-asp-semantics-splitting-set}
Given a program $P$, a set of atoms $U$ is a \emph{splitting set} of $P$ if for every rule $r$, where $h(r) \in U$, also theatoms corresponding to all body literals of $r$ are in $U$. The set of rules corresponding to $U$, i.e. the rules definingthe atoms in $U$, is called \emph{bottom} of $P$ with respect to $U$, denoted as $B_U(P)$. Consequently, $P \setminus B_U(P)$is called \emph{top} of $P$, which is denoted as $T_U(P)$.\\
\end{definition}

\begin{theorem}[Splitting Set Theorem, adapted from~\cite{splitting-sets}]
Given a program $P$ and splitting set $U$ which splits $P$ into bottom $B_U(P)$ and top $T_U(P) = P \setminus B_U(P)$. Then aset of atoms $A$ is an answer set if and only if $A = X \cup Y$ for sets $X$ and $Y$ where
\begin{itemize}
	\item $X \in AS(B_U(P))$, i.e. $X$ is an answer set of bottom $B_U(P)$ and
	\item $Y \in AS(T_U(P) \cup X)$, i.e. $Y$ is an answer set of the program resulting from adding $X$ as facts to $T_U(P)$ 
\end{itemize}	
\end{theorem}	

\begin{definition}[Nonground splitting set]
\label{def:prelims-asp-semantics-nonground-splitting-set}
Given a non-ground program $P$, we denote splitting sets as sets of predicates rather than atoms. 
For a given predicate $p$, we denote as $dep(p)$ the \emph{dependencies} of $p$:
 \[
	dep(p) = \{q~|~\exists r \in P: pred(h(r)) = p \land \exists l \in b(r): pred(l) = q\}
\]
Intuitively, the dependencies of a predicate $p$ are all predicates of which all ground instances must be known in order to compute all ground instances of $p$.
A set $S$ of predicates $p_1,\ldots,p_n$ is a splitting set of $P$ if the following holds. 
\[
	\forall p:  p \in S \Rightarrow dep(p) \in S
\]
A non-ground splitting set $S_{ng}$ is sematically equivalent to the ground splitting set $S_{grnd}$ one gets by taking all ground instances of all predicates in $S_{ng}$ from the ground program $grnd(P)$.
\end{definition}

\begin{example}[Partial evaluation using splitting sets]
\label{ex:prelims-nonstrat-splitting-sets}
Given program $P_{col}$ from Listing~\ref{lst:prelims-3col-var} in Example~\ref{ex:prelims-nonstrat}, let $S$ be the following (non-ground) splitting set:
\begin{align*}
	S = \{&coloring\_vertex/1,~coloring\_edge/2,~vertex/1,~exclude\_vertex/1, \\
		  &edge/2,~exclude\_edge/2\}
\end{align*}
Using $S$, we can split $P_{col}$ into bottom $B_S(P_{col})$, which is shown in Listing~\ref{lst:prelims-3col-var-bot}, and top $T_S(P_{col})$ in Listing~\ref{lst:prelims-3col-var-top}.
\begin{lstlisting}[style=asp-code, label={lst:prelims-3col-var-bot}, caption={The bottom part of $P_{col}$}]
vertex(a). vertex(b). vertex(c). vertex(d).
edge(a, b). edge(a, c). edge(a, d).
edge(b, c). edge(b, d). edge(c, d).
edge(X, Y) :- edge(Y, X).
	
exclude_vertex(d).
exclude_edge(V1, V2) :- edge(V1, V2), exclude_vertex(V1).
exclude_edge(V1, V2) :- exclude_edge(V2, V1).
	
coloring_vertex(V) :- vertex(V), not exclude_vertex(V).
coloring_edge(V1, V2) :- 
	edge(V1, V2), not exclude_edge(V1, V2).
\end{lstlisting}
Looking at $B_S(P_{col})$, we can observe that this sub-program of $P_{col}$ is now stratified, and can therefore be evaluated using the straight-forward computation employed in Example~\ref{ex:prelims-strat-eval}. We arrive at the following model for $B_S(P_{col})$:
\begin{align*}
	LM(B_S(P_{col})) = \{&coloring\_vertex(b),~exclude\_vertex(d),~edge(b, d), \\
						 &edge(a, b),~edge(c, d),~edge(c, b),~coloring\_edge(b, c),\\
						 &coloring\_edge(a, c),~coloring\_edge(b, a),~edge(a, d),\\
						 &coloring\_edge(c, a),~vertex(c),~	vertex(a),~edge(d, b), \\
						 &exclude\_edge(d, b),~exclude\_edge(c, d),~exclude\_edge(a, d),\\
						 &coloring\_vertex(c),~exclude\_edge(b, d),~coloring\_vertex(a),\\
						 &edge(a, c),~edge(b, c),~edge(b, a),~edge(d, c),coloring\_edge(a, b)\\
						 &coloring\_edge(c, b),~vertex(d),~exclude\_edge(d, a),~vertex(b)\\
						 &edge(c, a),~exclude\_edge(d, c),~edge(d, a)\}
\end{align*}		
\begin{lstlisting}[style=asp-code, label={lst:prelims-3col-var-top}, caption={The top part of $P_{col}$}]
% Guess colors
red(V) :- coloring_vertex(V), not green(V), not blue(V).
green(V) :- coloring_vertex(V), not red(V), not blue(V).
blue(V) :- coloring_vertex(V), not red(V), not green(V).
	
% Filter invalid guesses
:- coloring_vertex(V1), coloring_vertex(V2), 
	coloring_edge(V1, V2), red(V1), red(V2).
:- coloring_vertex(V1), coloring_vertex(V2), 
	coloring_edge(V1, V2), green(V1), green(V2).
:- coloring_vertex(V1), coloring_vertex(V2), 
	coloring_edge(V1, V2), blue(V1), blue(V2).
\end{lstlisting}	
In order to compute the answer sets of the complete program, by the splitting set theorem, we only have to compute the answer sets of $T_S(P_{col}) \cup pr(LM(B_S(P_{col})))$. A simple (but computationally expensive) way to do this would be to perform an exhaustive search over all combinations of ground instances of the rules from lines 2 to 4 and drop all model candidates where any of the constraints fire.
We finally get the following answer sets (filtered for predicates $red/1$, $green/1$ and $blue/1$):
\begin{align*}
	A_1 &= \{blue(c),~green(b),~red(a)\}\\
	A_2 &= \{blue(b),~green(c),~red(a)\}\\
	A_3 &= \{blue(b),~green(a),~red(c)\}\\
	A_4 &= \{blue(c),~green(a),~red(b)\}\\
	A_5 &= \{blue(a),~green(b),~red(c)\}\\
	A_6 &= \{blue(a),~green(c),~red(b)\}
\end{align*}	
\end{example}	

Expanding on Example~\ref{ex:prelims-nonstrat-splitting-sets}, it is clear that a stratifiable bottom with respect to some splitting set always exists - every program has at least the empty set as a trivial splitting set. We call the maximal stratifiable sub-program that only depends on facts (i.e. is a bottom w.r.t some splitting set) \gls{cbp}, see Definition~\ref{def:prelims-asp-semantics-cbp}.

\begin{definition}[Common Base Program, adapted from~\cite{partial-eval}]
\label{def:prelims-asp-semantics-cbp}
Given a splitting set $S$ of program $P$, the bottom $B_S(P)$ is called \emph{common base program}, i.e. $CBP(P)$ if it is stratified and maximal in the sense that adding any further rule to $B_S(P)$ would destroy the property of $B_S(P)$ of being stratified.
\end{definition}

What remains is to solve the remaining, non-stratifiable part of a program. State-of-the-art two-phased solvers such as Clingo employ solving techniques based on~\gls{cdnl} for this~\cite{clasp-cdnl}. The basic idea of \gls{cdnl} is to encode a ground program as a set of constraints called \emph{nogoods}, i.e. sets of literals that must not be contained in any answer set. Based on these nogoods, truth assignments over $H_B(P)$ are "guessed" and conflicting guesses are used to potentially learn new nogoods using techniques originating in SAT-solving. However, these techniques normally require an input program to be fully ground, and therefore do not lend themselves to lazy-grounding approaches. Alpha uses a solving approach that is inspired by \gls{cdnl}, but makes a number of modifications to apply the same principles in a lazy-grounding scenario. Section~\ref{subsec:prelims-lazygrounding-alpha-cdnl} gives a highlevel overview of how answer set search is realized in Alpha.

\subsection{Lazy-grounding answer set search}
\label{subsec:prelims-lazygrounding-alpha-cdnl}

Just like two-phased solvers, Alpha also uses \emph{nogoods} to encode rules and constraints. However, Alpha does not have a full grounding of the program it solves, which necessitates a number of modifications. Without a full grounding, a solver must be able to distinguish between atoms in an assignment (i.e. answer set candidate) that are \emph{true because some rule fired}, and atoms that \emph{must be true because some constraint does not permit otherwise} (but haven't been derived by a rule). Lazy-grounding solvers introduce a third truth value, \emph{must-be-true} (MBT), to reflect this. For an assignment to be an answer set, it must not contain any MBT values. Definitions~\ref{def:prelims-alpha-nogood} and~\ref{def:prelims-alpha-nogood-ruleencoding} formally describe nogoods and their use to represent rules in Alpha.

\begin{definition}[Alpha-Assignment, Nogood~\cite{lazy-cdnl}]
\label{def:prelims-alpha-nogood}	
An \emph{Alpha-Assignment}, in the following just \emph{assignment} is a sequence $A = \{sl1,\ldots,sl_n\}$ of literals $l_1\ldots,l_n$ preceded by a \emph{sign} $s \in \{T, M, F\}$. Intuitively, a signed literal $sl_i$ assigns the truth value $s$ to literal $l$. Possible truth values are \emph{true} ($T$), \emph{false} ($F$) and \emph{must-be-true} ($M$). Must-be-true is used as truth value for literals that are deemed by the solver to necessarily be true (e.g. because of a constraint precluding any other truth value), but there is no known firing rule (yet) which would allow assigning $T$. The \emph{boolean projection} $A^{\mathcal{B}}$ of an assignment $A$ is defined as: 
\[
	A^{\mathcal{B}} = \{ Ta~|~Ta \in A \lor Ma \in A\} \cup \{ Fa~|~Fa \in A\}
\]
\\
A \emph{nogood}, in the variant used by Alpha, is a set of signed literals intuitively characterizing a set of literals that may not occur in an assignment with the given truth values:
\[
	ng = \{ sl_1,\ldots,sl_n \}, s \in \{T, F\}
\]
Different from how nogoods are defined in classic two-phased solvers, a nogood in Alpha may optionally have a specifically designated "head" literal. Given a nogood where $sl_i$ is the head literal, we denote this as: $ng = \{ sl_1,\ldots,sl_n \}_i$. For a signed literal $sl$, we denote the literal with inverse sign as $\overline{sl}$.
An assignment $A$ \emph{satisfies} a nogood $ng$ if $ng \nsubseteq A^{\mathcal{B}}$. Furthermore, an assignment $A$ is a \emph{solution} to a set $\Delta$ of nogoods if $\{a~|~Ta \in A^{\mathcal{B}}\} \cap \{a~|~Fa \in A^{\mathcal{B}}\} = \emptyset$,  $\{a~|~Ta \in A^{\mathcal{B}}\} \cup \{a~|~Fa \in A^{\mathcal{B}}\} = A^{\mathcal{B}}$ and $\forall~ng \in \Delta: ng \nsubseteq A^{\mathcal{B}}$.
\end{definition}

\begin{definition}[Nogood representation of rules~\cite{lazy-cdnl}]
\label{def:prelims-alpha-nogood-ruleencoding}		
In order to represent a ground body of a rule, Alpha introduces new atoms, denoted $\beta(r,\sigma)$ for a rule $r$ and variable substitution $\sigma$.\\
Given a rule $r$ with head $h(r) = a_0$, positive body $b^{+}(r) = a_1,\ldots,a_k$ and negative body $b^{-}(r) = a_{k+1},\ldots,a_n$, the \emph{nogood representation} of $r$, $ng(r)$ is defined as follows:
\begin{align*}
	ng(r) = \{&\{F\beta(r,\sigma),Ta_1,\ldots,Ta_k,Fa_{k+1},\ldots,Fa_n\}_1,\{Fa_0,T\beta(r,\sigma)\},\\
			  &\{T\beta(r,\sigma),Fa_1\},\ldots,\{T\beta(r,\sigma),Fa_k\},\\
			  &\{T\beta(r,\sigma),Ta_{k+1}\},\ldots,\{T\beta(r,\sigma),Ta_n\}\}
\end{align*}	
\end{definition}


\paragraph{Lazy Grounding and solving in Alpha~\cite{alpha-techniques}}
Alpha's grounder always calculates ground substitutions for all rules that are \emph{applicable} with respect to a (partial) assignment $A$. A rule $r$ is said to be applicable w.r.t $A$, if, given a ground substitution $\sigma$ $b^{+}(r\sigma) \subseteq A^{\mathcal{B}}$ and $b^{-}(r\sigma) \cap \{a~|~Ta \in A^{\mathcal{B}}\} = \emptyset$, i.e. a ground rule is applicable, if its positive body is satisifed and its negative body is not contradicted by an assignment.
When solving a program, Alpha's grounder constructs an initial partial assignment from all facts and the model of the previously solved \gls{cbp}. Based on this partial assignment, ground instances for applicable rules are computed and translated into nogoods. The partial assignment and generated nogoods are passed to the solver. The solver then first applies propagation, i.e. extends assignment $A$ based on unit nogoods as described in Definition~\ref{def:prelims-alpha-nogood-unitness}. Then, if a conflict between the (possibly extended) assignment and the current set of nogoods exists, the conflict is analyzed, a new nogood describing the conflict cause is added, and the solver \emph{backtracks} (i.e. retracts enough of the assignment to get to a conflict-free state). If there are no conflicts, and applicable rules exist, the solver guesses (based on a heuristic), which rule to apply. If there are no applicable rules or unassigned atoms, and no atom is assigned \emph{must-be-true}, the solver has found an answer set. In this case, the answer set is stored, a new nogood which prevents finding the same answer set again is added, and the solver backtracks. Algorithm~\ref{alg:prelims-alpha-search} gives a highlevel summary of Alpha's answer set search procedure.

\begin{definition}[Weak and strongly unit nogoods~\cite{lazy-cdnl}]
\label{def:prelims-alpha-nogood-unitness}	
Let $ng$ be a nogood $ng = \{sl_1,\ldots,s_n\}$ and $A$ an assignment. Then
\begin{itemize}
	\item $ng$ is \emph{weakly unit} under $A$ for $sl$ if $ng \setminus A^{\mathcal{B}} = \{sl\}$ and $\overline{sl} \notin A^{\mathcal{B}}$
	\item $ng$ is \emph{strongly unit} under $A$ for $sl$ if $sl$ is designated the "head" of $ng$, $ng \setminus A = \{sl\}$ and $\overline{sl} \notin A$
\end{itemize}	
Intuitively, if a nogood is unit under an assignment $A$, it forces a truth value for the single literal $sl$ which is not yet assigned (as otherwise, the nogood would be violated). In Alpha, the notions of weak and strong unitness are used to distinguish between nogoods forcing a literal to be set to \emph{must-be-true} (if implied by a weakly unit nogood) and \emph{true} (if implied by a strongly unit nogood)
\end{definition}	

\begin{algorithm}[!h]
\SetAlgoLined
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\SetKwRepeat{Do}{do}{while}
\Input{A non-ground program $P$}
\Output{The answer sets $AS(P)$ of $P$}
Iniitialize $AS = \emptyset$, assignment $A$, nogood storage $\Delta$.\\
Run lazy grounder, obtain initial nogoods $\Delta$ from facts.\\
\While{search space not exhausted}{
	Propagate on $\Delta$, extending $A$. \\
	\uIf{conflicting nogood exists}{
		Analyze conflict, learn new nogood, backtrack. \\
	}
	\uElseIf{propagation extended $A$}{
		Run lazy grounder w.r.t $A$ to obtain new nogoods to extend $\Delta$.\\
	}
	\uElseIf{applicable rule exists}{
		Guess rule to fire according to heuristic.\\
	}
	\uElseIf{unassigned atom exists}{
		Assign all unassigned atoms to false.\\
	}
	\uElseIf{no atom assigned must-be-true in $A$}{
		$AS \leftarrow AS \cup \{A\}$
		Answer set found, add enumeration nogood and backtrack. 
	}
	\Else{
		Backtrack.
	}
}
\textbf{return} $AS$
\caption{Alpha's answer set search procedure~\cite{alpha-techniques}}\label{alg:prelims-alpha-search}
\end{algorithm}

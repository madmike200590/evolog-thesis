\section{Answer Set Programming}

When speaking of \gls{asp}, we nowadays mostly refer to the language specfied by the ASP-Core2 standard~\cite{asp-core2}. It uses the \emph{stable model semantics} by Gelfond and Lifschitz~\cite{stable-models} as a formal basis and enhances it with support for advanced concepts such as disjunctive programs, aggregate literals and weak constraints. This chapter describes the input language supported by the Alpha solver, which will serve as the basis on which we will define the Evolog language.

\subsection{Syntax}
\label{subsec:prelims-asp-syntax}

\begin{definition}[Integer numeral]
\label{def:prelims-asp-syntax-int}
An \emph{integer numeral} in the context of an \gls{asp} program is a string matching the regular expression:
\begin{lstlisting}[style=code]
(-)?[0-9]+
\end{lstlisting}
The set of all valid integer numerals is denoted as $\INTs$.
\end{definition}

\begin{definition}[Identifier]
\label{def:prelims-asp-syntax-id}
An \emph{identifier} in the context of an \gls{asp} program is a string matching the regular expression:
\begin{lstlisting}[style=code]
[a-z][a-zA-Z0-9\_]*
\end{lstlisting}
The set of all valid identifiers is denoted as $\IDs$.
\end{definition}

\begin{definition}[Variable Name]
\label{def:prelims-asp-syntax-var}
A \emph{variable name} in the context of an \gls{asp} program is a string matching the regular expression:
\begin{lstlisting}[style=code]
[A-Z][a-zA-Z0-9\_]*
\end{lstlisting}
The set of all valid variable names is denoted as $\VARs$.
\end{definition}

\begin{definition}[Term]
\label{def:prelims-asp-syntax-term}
A \emph{term} is inductively defined as follows:
\begin{itemize}
	\item Any \emph{constant} $c \in (\INTs \cup \IDs)$ is a term.
	\item Any \emph{variable} $v \in \VARs$ is a term.
	\item Given terms $t_1, t_2$, any \emph{artihmetic expression} $t_1 \oplus t_2$ with $\oplus \in \{+, - , *, /, **\}$ is a term.
	\item Given terms $t_1, t_2$, any \emph{interval expression} $t_1 \ldots t_2$ is a term.
	\item For function symbol $f \in \IDs$ and argument terms $t_1, \ldots, t_n$, the \emph{functional expression} $f(t_1, \ldots, t_n)$ is a term.
\end{itemize}
\end{definition}

\begin{definition}[Subterms]
\label{def:prelims-asp-syntax-subterms}
Given a term $t$, the set of \emph{subterms} of $t$, $st(t)$, is defined as follows:
\begin{itemize}
	\item If $t$ is a \emph{constant} or \emph{variable}, $st(t) = \{t\}$.
	\item If $t$ is an \emph{arithmetic expression} $t_1 \oplus t_2$, $st(t) = st(t_1) \cup st(t_2)$.
	\item If $t$ is an \emph{interval expression} $t_1 \ldots t_2$, $st(t) = st(t_1) \cup st(t_2)$.
	\item If $t$ is a \emph{functional expression} with argument terms $t_1, \ldots, t_n$, $st(t) = st(t_1) \cup \ldots \cup st(t_n)$.
\end{itemize}
A term is called \emph{ground} if it is variable-free, i.e. none of its subterms is a variable.
\end{definition}

\begin{definition}[Basic Atom]
\label{def:prelims-asp-syntax-atom}
Given a predicate symbol $p \in \IDs$ and argument terms $t_1,\ldots,t_n$, the expression
\[
	p(t_1,\ldots,t_n)
\]
is called a \emph{atom}. An atom is ground if all of its argument terms are ground. A ground atom with predicate $p$ is called an \emph{instance} of $p$.
\end{definition}

\begin{definition}[Comparison Atom]
\label{def:prelims-asp-syntax-cmp-atom}
Given terms $t_1$ and $t_2$ and comparison operator $\odot$ where $\odot \in \{ <, \leq, =, \geq, >, \neq \}$, the expression
\[
	t_1 \odot t_2
\]
is called a \emph{comparison atom}. Syntactically, a comparison atom is a regular atom where the predicate symbol (i.e. comparison operator) is written in infix- rather than prefix-notation.
\end{definition}

\begin{definition}[External Atom]
\label{def:prelims-asp-syntax-ext-atom}
Given an \emph{external predicate name} $\mathit{ext}$, \emph{input terms} $t_1,\ldots,t_n$ and \emph{output terms} $t_{n+1},\ldots,t_m$, the expression
\[
	\&\mathit{ext}[t_1,\ldots,t_n](t_{n+1},\ldots,t_m)
\]
is called an \emph{external atom}. Syntacticaly, external atoms are regular atoms where $\&\mathit{ext}$ is the predicate symbol and $t_1,\ldots,t_m$ are argument terms.
\end{definition}

\begin{definition}[Literal]
\label{def:prelims-asp-syntax-literal}
A literal in \gls{asp} is an atom $a$ or ("default"-)negated atom $\NOT\ a$. Literals wrapping comparison- or external atoms are called \emph{fixed interpretation literals}. Given a literal $l$, the expression $pred(l)$ refers to the predicate of $l$ (e.g $pred(p(a)) = p/1$).
\end{definition}

\begin{definition}[Rule, Program]
\label{def:prelims-asp-syntax-rule}
A \emph{rule} is an expression of form
\[
	a_H \leftarrow b_1,\ldots,b_n.
\]
for $n \geq 0$, where the \emph{rule head} $a_H$ is an atom and the \emph{rule body} $b_1,\ldots,b_n$ is a set of literals. An \gls{asp} \emph{program} is a set of rules. A rule with an empty body is called a \emph{fact}. A rule is \emph{ground} if both its head atom and all of its body literals are ground. By the same reasoning, a program is ground if all of its rules are ground.\\
Given a rule $r$, he refer to the head of $r$ as $h(r)$ and the body of $r$ as $b(r)$. Furthermore, $b^+(r)$ is used to reference the set of \emph{positive body literals} of $r$, while $b^-(r)$ references the \emph{negative body literals}. 
\end{definition}

\begin{definition}[Constraint]
\label{def:prelims-asp-syntax-constraint}
A \emph{constraint} is a special form of rule, written as a rule with an empty head, i.e.
\[
	\leftarrow b_1,\ldots,b_n.
\]
It is syntactic sugar for
\[
	q \leftarrow b_1,\ldots,b_n, \NOT\ q.
\]
where $q$ is a propositional constant not occurring in any other rule in the program.
\end{definition}

\subsection{Semantics}
\label{subsec:prelims-asp-semantics}

\begin{definition}[Herbrand Universe]
\label{def:prelims-asp-semantics-hu}
The Herbrand Universe $HU_P$ of a Program $P$ is the set of all ground terms that can be constructed with respect to Definitions~\ref{def:prelims-asp-syntax-int},~\ref{def:prelims-asp-syntax-id} and \ref{def:prelims-asp-syntax-term}.
Note that most papers use stricter definitions of the Herbrand Universe where $HU_P$ consists only of terms constructible from constants occurring in $P$. The broader definition used here is chosen for ease of definition with respect to some of the extensions introduced in Section~\ref{sec:evolog-actions}.
\end{definition}

\begin{definition}[Herbrand Base]
\label{def:prelims-asp-semantics-hb}
The Herbrand Base $HB_P$ of a Program $P$ is the set of all ground atoms that can be constructed from the Herbrand Universe $HU_P$ according to definition~\ref{def:prelims-asp-syntax-atom}. 
\end{definition}

\begin{definition}[Herbrand Interpretation]
\label{def:prelims-asp-semantics-herbrand-interpretation}
A Herbrand Interpretation is a special form of first order interpretation where the domain of the interpretation is a Herbrand Universe and the interpretation of a term is the term itself, i.e. the corresponding element of $HU_P$. Intuitively, Herbrand Interpretations constitute listings of atoms that are true in a given program. Since the domain of a Herbrand Interpretation is always the Herbrand Universe $HU_P$, we only need to give a predicate interpretation for the predicates occurring in a program $P$ in oder to fully specify a Herbrand Interpretation. We can therefore denote Herbrand Interpretations as sets of atoms $I \subseteq HB_P$.
\end{definition}

\subsubsection{Grounding}
\label{subsubsec:prelims-grounding}
Given a program $P$ containing variables, \emph{grounding} refers to the process of converting $P$ into a semantically equivalent propositional, i.e. variable-free, program.

\begin{definition}[Substitution, adapted from~\cite{lazy-cdnl}]
\label{def:prelims-asp-semantics-substitution}
A substitution $\sigma: \VARs \mapsto (\IDs \cup \INTs)$ is a mapping from variables to constants. For a atom $a$, applying a a substitution results in a substituted atom $a\sigma$ in which variables are replaced according to $\sigma$. Substitutions are applied to rules  by applying them to every individual atom or literal within the rule. By the same mechanism, we can apply substitutions to programs by applying the to all rules.
\end{definition}

\begin{definition}[Grounding]
\label{def:prelims-asp-semantics-grounding}
Given a rule $r$, the \emph{grounding} of $r$, $\mathit{grnd}(r)$, is a set of substitutions $S$, such that the set of ground rules resulting from applying the substitutions in $S$ is semantically equivalent to $r$. In a slight abuse of terminology, \emph{grounding} in this work also refers to the set of ground rules resulting from applying $S$ as well as the process of finding said set.
\end{definition}

\subsubsection{Stable Model Semantics}
\label{subsubsec:prelims-asp-semantics-stable-models}

\begin{definition}[Fixed interpretation literals]
\label{def:prelims-asp-semantics-fixedinterpretation-literals}	
Fixed interpretation literals, i.e. comparison- and external literals, respectively, are interpreted by means of a program-independent oracle function $f_O : H_{U}(P)^{*} \mapsto \{ \top, \bot \}$, i.e. a fixed interpretation literal with argument terms $t_1,\ldots,t_n$ has the same truth value under all interpretations.
\end{definition}

\begin{definition}[Truth of Atoms and Literals]
\label{def:prelims-asp-semantics-truth}
A positive ground literal $l$ with atom $a$ is true w.r.t. a Herbrand Interpretation $I$, i.e. $I \models l$ if
\begin{itemize}
	\item $a$ is a basic atom contained in $I$, i.e. $a \in I$,
	\item $a$ is a fixed interpretation literal with terms $t_1,\ldots,t_n$ and $f_O(t_1,\ldots,t_n) = \top$.
\end{itemize} 
For a negative ground literal $\NOT\ a$, the reverse holds, i.e. $I \models \NOT\ a$ if
\begin{itemize}
	\item $a$ is a basic atom not contained in $I$, i.e. $a \notin I$,
	\item $a$ is a fixed interpretation literal with terms $t_1,\ldots,t_n$ and $f_O(t_1,\ldots,t_n) = \bot$.
\end{itemize} 
A set of literals $L$ is true w.r.t. an interpretation $I$ if $I \models l$ holds for every literal $l \in L$. 
\end{definition}

\begin{definition}[Positive Logic Program]
\label{def:prelims-asp-semantics-positive-program}
A \emph{positive} logic program is a program according to Definition \ref{def:prelims-asp-syntax-rule}, where all rule bodies are positive, i.e. no rule body contains a negated atom.
\end{definition}

\begin{definition}[Immediate Consequence Operator, adapted from~\cite{asp-primer}]
\label{def:prelims-asp-semantics-immediate-consequence}
Given a Herbrand Interpretation $I$ and a ground positive logic program $P$, the immediate  consequence operator $T_P(I)$ defines a monotonic function $T_P: 2^{HB_P} \mapsto 2^{HB_P}$ such that
\[
	T_P(I) = \{h(r)\ |\ r \in P \land I \models b(r)\}
\]
i.e. the result set of applying $T_P$ with a Herbrand Interpretation $I$ contains the heads of all rules whose body is true under $I$.
\end{definition}

\begin{definition}[Least Model of positive logic programs]
\label{def:prelims-asp-semantics-least-model}
The least model $LM(P)$ of a (ground) positive logic program $P$ is the least fixpoint of the $T_P$ operator  of $P$, i.e. the set toward which the sequence $\langle T^{i}_{P} \rangle$, with $i \geq 0$, $T^{0}_P = \emptyset$ and $T^{i}_P = T_P(T^{i-1}_P)$ for $i \geq 1$, converges. The existence of said fixpoint and its characterisation as limit of $\langle T^{i}_{P} \rangle$ follow from the fixpoint theorems of Knaster, Tarski and Kleene, respectively.
\end{definition}

\begin{definition}[Gelfond-Lifschitz Reduct, adapted from~\cite{stable-models} and~\cite{asp-primer}]
\label{def:prelims-asp-semantics-gl-reduct}
Given a ground \gls{asp} program $P$ and a Herbrand Interpretation $I$, the \emph{Gelfond-Lifschitz-Reduct} ("GL-reduct") $P^{I}$ of $P$ with respect to $I$ is the program obtained by:
\begin{itemize}
	\item removing from $P$ all rules $r$ that are "blocked", i.e. $I \not\models l$ for some literal $l \in b^{-}(r)$ 
	\item and removing the negative body of all other rules.
\end{itemize}
Note that $P^{I}$ is a positive logic program.
\end{definition}

\begin{definition}[Answer Set~\cite{stable-models}~\cite{asp-primer}]
\label{def:prelims-asp-semantics-answer-set}
A Herbrand Interpretation $I$ of an \gls{asp} program $P$ is an \emph{answer set} or \emph{stable model} of $P$ iff it is the least model $LM(P^I)$ of the GL-reduct $P^I$ of $P$. We denote the set of Answer Sets of a program $P$ as $\mathit{AS}(P)$.
\end{definition}

% \subsection{Two-phased ASP solving}
% In traditional \gls{asp} solving systems such as SModels~\cite{smodels}, DLV~\cite{dlv} or Clingo~\cite{clingo}, grounding an input program and solving the resulting propositional program are distinct sequential steps in the overall solving process. Consequently, in order to obtain answer sets of a program, one has to calculate a grounding for the entire program first, and can only then start the actual solver. Since the grounding of an arbitrary program may be exponentially larger than the nonground program or, in some extreme cases, not even finite, calculating a full grounding is often not feasible, especially for programs where only very few ground rules can actually fire. Lazy-grounding systems like Alpha try to alleviate this by interleaving the grounding- and solving steps and ideally ground only as much of the input programs as is necessary to find all answer sets.

% \subsection{Conceptual solving workflow in Alpha}

% The formal basis of lazy-grounding architectures lies in the notion of a \emph{computation sequence}, i.e. a set of rules firing in a given order in order to get to an interpretation that is an answer set. Definition \ref{def:prelims-asp-semantics-compseq} formally introduces computation sequences.

% Obviously, computation sequences can be easily found by simple iterative application of the $T_P$ operator for programs that do not use negation in rules. However, since in general once negation comes into play, solvers may have to retract assignments of atoms ("backtrack"), over the course of the solving process. \todo{Example of mutually blocking rules!} Lazy-grounding solvers suffer from a performance penalty compared to two-phased systems in that respect. This penalty results from algorithms based on \gls{cdnl}~\cite{clasp-cdnl} achieving higher performance since conflicts occur faster and more nogoods can be learned from them with a full grounding available. A key challenge in designing lazy-grounding systems is therefore identifying classes of programs as well as groups of rules within programs that can be evaluated using simplified deterministic algorithms in order to minimize the number of potential backtracks.

\section{The Alpha System for Lazy-Grounding Answer Set Solving}

The theoretical notion underlying lazy-grounding answer-set solving is that of a \emph{Computation Sequence}, which is formalized in Definition~\ref{def:def:prelims-asp-semantics-compseq}. Intuitively, a computation sequence is a sequence of (ground) rules firing, such that, at the end, the atoms derived by the rules from the computation sequence (together with all facts of the program) constitute an answer set.

\begin{definition}[Computation Sequence, adapted from~\cite{lazy-cdnl} and~\cite{asperix-fw-chain}]
	\label{def:prelims-asp-semantics-compseq}
	Let $P$ be an \gls{asp} program and $S = (A_0,\ldots,A_{\infty})$ a sequence of assignments, i.e. herbrand interpretations denoted by a set of atoms assumed to be true, then $S$ is called a \emph{computation sequence} iff
	\begin{itemize}
		\item $A_0 = \emptyset$
		\item $\forall i \geq 1: A_i \subseteq T_P(A_{i - 1})$, i.e. every $A_i$ is a consequence of its predecessor in the sequence,
		\item $\forall i \geq 1: A_{i - 1} \subseteq A_{i}$, i.e. S is monotonic,
		\item $A_{\infty} = \cup^{\infty}_{i = 0} A_i = T_P(A_{\infty})$, i.e. $S$ converges toward a fixpoint and
		\item $\forall i \geq 1: \forall a \ \in A_i \setminus A_{i - 1}, \exists r \in P: h(r) = a \land \forall j \geq i - 1: A_j \models a$, i.e. applicability of rules is persistent.
	\end{itemize}
	$A_{\infty}$ is an answer set of $P$ iff $S$ is a computation sequence. Note that there may exist an arbitrary number of computation sequences leading to the same answer set.
\end{definition}

It is easily observed that, in order to calculate computation sequences, one does not need a full grounding of the input program. Since facts are ground by definition, rules that only depend on facts can be grounded (and evaluated) based on facts alone. The same holds for rules depending on facts and rules from the previous step, etc. Example~\ref{ex:compseq-naive-calc} demonstrates how a computation sequence for a very simple positive program can be caluclated using a naive algorithm based on repeated application of the $T_P$-operator.

\begin{example}[Lazy-grounding a positive logic program]
\label{ex:compseq-naive-calc}
In order to illustrate the use of computation sequences for lazy-grounding, we consider the program $P$ in Listing~\ref{lst:compseq-naive-calc}. We denote the rule on line 2 as $r_1$ and the one on line 3 as $r_2$.
\begin{lstlisting}[style=asp-code, label={lst:compseq-naive-calc}, caption={A positive, non-ground program}]
p(a). p(b). p(c). q(b). q(c). q(d).
r(X) :- p(X), q(X).
t(X, Y) :- r(X), r(Y), X != Y.	
\end{lstlisting}
Starting from the set of facts on line 1, which we denote as $F$, we now look for rules that only depend on predicates in $F$ (i.e. body literals only have predicates for which we already know ground instances). The only applicable rule is $r_1$ for which we  can construct ground instances \texttt{r(b) :- p(b), q(b)} and \texttt{r(c) :- p(c), q(c)}. Continuing this process, now based on the set $F \cup \{r(b),r(c)\}$, we find ground instances \texttt{t(b, c) :- r(b), r(c), b != c} and \texttt{t(c, b) :- r(c), r(b), c != b} of $r_2$. We thus arrive at the following computation sequence:
\begin{align*}
	A_0 &= \{p(a), p(b), p(c), q(b), q(c), q(d)\},\\
	A_1 &= \{p(a), p(b), p(c), q(b), q(c), q(d), r(b), r(c)\},\\
	A_2 &= \{p(a), p(b), p(c), q(b), q(c), q(d), r(b), r(c), t(b, c), t(c, b)\}\\
\end{align*}	
The last element of the sequence, $A_2$ is the sole answer set of $P$.
\end{example}	

While the intuitive approach from Example~\ref{ex:compseq-naive-calc} clearly works for positive programs, things get more complicated when negation is involved. Consider the following program:
\begin{lstlisting}[style=asp-code]
	p(a). p(b). p(c). q(c).
	s(X) :- p(X), q(X).
	t(X) :- p(X), not s(X).
\end{lstlisting}
In order to arrive a the correct answer set $A = \{p(a), p(b), p(c), q(c), s(c), t(a), t(b)\}$, one has to first evaluate all rules that could potentially derive instances of $s/1$, before starting to evaluate the last rule, in order to end up with a valid computation sequence. Evaluation orders for this kind of programs can be calculated using the notion of \emph{stratification}~\cite{stratification} which is described in detail in Section~\ref{sec:stratified-evaluation}.

\subsection{Structural Dependency Analysis and Stratified Evaluation}
\label{subsec:stratified-evaluation}

In a nutshell, a \emph{stratifiable} logic program is a program, for which we can calculate a partition into sub-programs, such that, when evaluating the sub-programs sequentially, one always ends up with a correct computation sequence. Definition~\ref{def:prelims-asp-semantics-stratification} formally characterizes stratifiable programs.

\begin{definition}[Stratifiable answer set program, as stated in~\ref{partial-eval}, adapted from\cite{stratification},~\cite{asp-primer}]
\label{def:prelims-asp-semantics-stratification}	
Given a program $P = \{r_{0}, ..., r_{n}\}$, $P$ is called \emph{stratifiable} iff there is a partition $P = P_{S_0} \cup\ ... \cup\ P_{S_n}$ so that for each $0 \le i \leq n$ the following holds:
\begin{itemize}
	\item For every positive body literal $l_{b}$ of every rule in $P_{S_i}$, every rule that derives instances of the predicate $\mathit{pred}(l_{b})$, i.e. where the predicate of the head atom $\mathit{pred}(a_H)$ is $\mathit{pred}(l_{b})$, is contained in some $P_{S_j}$ with $j \leq i$.
	\item For every negative body literal $\mathit{not}\ l_{b}$ of every rule in $P_{S_i}$, every rule that derivesinstances of the predicate $\mathit{pred}(l_{b})$, i.e. where the predicate of the head atom $\mathit{pred}(a_H)$is $\mathit{pred}(l_{b})$, is contained in some $P_{j}$ with $j < i$.
\end{itemize}
The individual subprograms $P_{S_i}$ are called strata. A \emph{stratification} $S = \{P_{S_0},\ldots, P_{S_n}\}$refers to the set of all strata making up a partition which satisfies the criteria above.
\end{definition}

The least model, i.e. the sole answer set, of a stratifiable program can be computed by sequentially applying the immediate consequence operator to every stratum, see Definition~\ref{def:prelims-asp-semantics-stratified-compseq}.

\begin{definition}[Least model of stratifiable programs, adapted from~\cite{asp-primer}]
\label{def:prelims-asp-semantics-stratified-compseq}
Let $P_{strat}$ be a stratifiable program for which a stratification $S = \{P_{S_0},\ldots,P_{S_n}\}$ exists and let $T_{P_{S_i}}$ be the immediate consequence operator for the sub-program defined by stratum $P_{S_i}$. Furthermore, for a model $M$, let $pr(M)$ be the program consisting of the facts representing the atoms in $M$.
Then the least model $LM(P_{strat})$ of $P_{strat}$ is defined as follows.
The sequence $\langle M_{S_i} \rangle,\ 0 \leq i \leq n$ with $M_{S_0} = \mathit{lfp}(T_{P_{S_0}})$ and $M_{S_i} = \mathit{lfp}(T_{(P_{S_{i}} \cup\ pr(M_{S_{i-1}}))})$ for all $1 \leq i \leq n$ defines the (iterative) least model for each stratum. The least model $LM(P_{strat})$ of program $P_{strat}$ is then the iterative least model of the highest stratum $M_{S_n}$, i.e. the end of the sequence $\langle M_{S_i} \rangle$.
\end{definition}

Since the evaluation mode described in Definition~\ref{def:prelims-asp-semantics-stratified-compseq} does not require any backtracking, i.e. the result of each step is part of the final result, we observe that te intermediate results of the immediate consequence operator yield a computation sequence for $P$. Example~\ref{ex:prelims-strat-eval} illustrates evaluation of a short stratifiable program.

\begin{example}[Evaluating a stratified program]
\label{ex:prelims-strat-eval}	
Consider the program $P$ from Listing~\ref{lst:prelims-strat-eval}.
\begin{lstlisting}[style=asp-code, label={lst:prelims-strat-eval}, caption={A stratifiable program.}]
p(a). p(b). p(c). q(c). q(d).

s(X) :- p(X), q(X).
t(X) :- p(X), not s(X).
u(X) :- q(X), not p(X).

v(X, Y) :- t(X), u(Y), X != Y.
\end{lstlisting}
A possible stratification $S$ of $P$ could look as follows:
\begin{align*}
	S_0 = \{&p(a).~p(b).~p(c).~q(c).~q(d). \\
			&s(X)~\leftarrow~p(X),~q(X).\} \\
	S_1 = \{&t(X)~\leftarrow~p(X),~not~s(X). \\
			&u(X)~\leftarrow~q(X),~not~p(X).\} \\
	S_2 = \{&v(X, Y)~\leftarrow~t(X),~u(Y),~X~!=~Y.\}
\end{align*}
In this case, the least model of $P$ can be calculated using the method from Definition~\ref{def:prelims-asp-semantics-stratified-compseq}. The individual results of the $T_P$ operator constitute a computation sequence.
\begin{align*}
	T_{P_{S_0}}^1 &= T_{P_{S_0}}(\emptyset) = \{p(a), p(b), p(c), q(c), q(d)\} \\
	T_{P_{S_0}}^2 &= T_{P_{S_0}}(T_{P_{S_0}}^1) = \{p(a), p(b), p(c), q(c), q(d), s(c)\} \\
	T_{P_{S_0}}^3 &= T_{P_{S_0}}(T_{P_{S_0}}^2) = \{p(a), p(b), p(c), q(c), q(d), s(c)\} = lfp(T_{P_{S_0}})\\
	\\
	T_{P_{E1}} &= T_{P_{S_1\cup pr(lfp(T_{P_{S_0}}))}}\\
	T_{P_{E1}}^1 &= T_{P_{E1}}(\emptyset) = \{p(a), p(b), p(c), q(c), q(d), s(c)\} \\
	T_{P_{E1}}^2 &= T_{P_{E1}}(T_{P_{E1}}^1) = \{p(a), p(b), p(c), q(c), q(d), s(c), t(a), t(b), u(d)\} \\
	T_{P_{E1}}^3 &= T_{P_{E1}}(T_{P_{E1}}^2) = \{p(a), p(b), p(c), q(c), q(d), s(c), t(a), t(b), u(d)\} = lfp(T_{P_{E1}}) \\
	\\
	T_{P_{E2}} &= T_{P_{S_2\cup pr(lfp(T_{P_{E1}}))}}\\
	T_{P_{E2}}^1 &= T_{P_{E2}}(\emptyset) = \{p(a), p(b), p(c), q(c), q(d), s(c), t(a), t(b), u(d)\} \\
	T_{P_{E2}}^2 &= T_{P_{E2}}(T_{P_{E2}}^1) = \{p(a), p(b), p(c), q(c), q(d), s(c), t(a), t(b), u(d), v(a, d), v(b, d)\} \\
	T_{P_{E2}}^3 &= T_{P_{E2}}(T_{P_{E2}}^2) = \{p(a), p(b), p(c), q(c), q(d), s(c), t(a), t(b), u(d), v(a, d), v(b, d)\} = lfp(T_{P_{E2}})\\
	\\
	LM(P) &= lfp(T_{P_{E2}})
\end{align*}	
\end{example}	

However, in general, ASP programs are not stratifiable. Example~\ref{ex:prelims-nonstrat} shows a typical non-stratifiable program.

\begin{example}[A non-stratifiable program]
\label{ex:prelims-nonstrat}
Consider a variant of the well-known 3-coloring problem for undirected graphs, where some vertices "stay blank", i.e. they are excluded from coloring. Essentially, prior to calculating actual colorings, we remove all ignored vertices and their corresponding edges from the graph and color only the resulting subgraph. Program $P_{col}$ in Listing~\ref{lst:prelims-3col-var} shows a possible encoding of this problem.
\begin{lstlisting}[style=asp-code, label={lst:prelims-3col-var}, caption={Graph 3-coloring with excluded vertices}]
vertex(a). vertex(b). vertex(c). vertex(d).
edge(a, b). edge(a, c). edge(a, d).
edge(b, c). edge(b, d). edge(c, d).
edge(X, Y) :- edge(Y, X).

exclude_vertex(d).
exclude_edge(V1, V2) :- edge(V1, V2), exclude_vertex(V1).
exclude_edge(V1, V2) :- exclude_edge(V2, V1).

coloring_vertex(V) :- vertex(V), not exclude_vertex(V).
coloring_edge(V1, V2) :- 
	edge(V1, V2), not exclude_edge(V1, V2).

% Guess colors
red(V) :- coloring_vertex(V), not green(V), not blue(V).
green(V) :- coloring_vertex(V), not red(V), not blue(V).
blue(V) :- coloring_vertex(V), not red(V), not green(V).

% Filter invalid guesses
:- coloring_vertex(V1), coloring_vertex(V2), 
	coloring_edge(V1, V2), red(V1), red(V2).
:- coloring_vertex(V1), coloring_vertex(V2), 
	coloring_edge(V1, V2), green(V1), green(V2).
:- coloring_vertex(V1), coloring_vertex(V2), 
	coloring_edge(V1, V2), blue(V1), blue(V2).
\end{lstlisting}
Clearly, $P_{col}$ is not stratifiable - the color assignment rules cyclically depend on each other through negated body literals. In other words, the rules on lines 15 to 17 are \emph{mutually exclusive}, i.e. a solver has to \emph{choose} which of the three should fire for a given ground instance of $coloring\_vertex/1$.
\end{example}

The program from Example~\ref{ex:prelims-nonstrat} can not be evaluated by iterative fixpoint-calculation as in Example~\ref{ex:prelims-strat-eval} becuase it is not stratifiable. However, it is still possible to evaluate at least a part of it using this method, rather than a computationally more complex "trial-and-error"-approach. This partial evaluation approach uses \emph{splitting sets}, which are characterized in Definition~\ref{def:prelims-asp-semantics-splitting-set}. Intuitively, a splitting set $S$ is a set of atoms, such that if an atom $a$ is in $S$, also all atoms it depends on (i.e. body atoms of rules deriving $a$) are in $S$. By the splitting set theorem, a splitting sets lets us partition a program $P$ such that it can be evaluated incrementally, by first evaluating the bottom $B_U(P)$ and then the top $T_U(P)$. Since this section deals with non-ground programs specifically, we also give an adapted definition for splitting sets of nonground programs, see Definition~\ref{def:prelims-asp-semantics-nonground-splitting-set}. Example~\ref{ex:prelims-nonstrat-splitting-sets} applies the splitting set theorem to the program from Example~\ref{ex:prelims-nonstrat}.

\begin{definition}[Splitting Set, adapted from~\cite{splitting-sets}]
\label{def:prelims-asp-semantics-splitting-set}
Given a program $P$, a set of atoms $U$ is a \emph{splitting set} of $P$ if for every rule $r$, where $h(r) \in U$, also theatoms corresponding to all body literals of $r$ are in $U$. The set of rules corresponding to $U$, i.e. the rules definingthe atoms in $U$, is called \emph{bottom} of $P$ with respect to $U$, denoted as $B_U(P)$. Consequently, $P \setminus B_U(P)$is called \emph{top} of $P$, which is denoted as $T_U(P)$.\\
\end{definition}

\begin{theorem}[Splitting Set Theorem, adapted from~\cite{splitting-sets}]
Given a program $P$ and splitting set $U$ which splits $P$ into bottom $B_U(P)$ and top $T_U(P) = P \setminus B_U(P)$. Then aset of atoms $A$ is an answer set if and only if $A = X \cup Y$ for sets $X$ and $Y$ where
\begin{itemize}
	\item $X \in AS(B_U(P))$, i.e. $X$ is an answer set of bottom $B_U(P)$ and
	\item $Y \in AS(T_U(P) \cup X)$, i.e. $Y$ is an answer set of the program resulting from adding $X$ as facts to $T_U(P)$ 
\end{itemize}	
\end{theorem}	

\begin{definition}[Nonground splitting set]
\label{def:prelims-asp-semantics-nonground-splitting-set}
Given a non-ground program $P$, we denote splitting sets as sets of predicates rather than atoms. 
For a given predicate $p$, we denote as $dep(p)$ the \emph{dependencies} of $p$:
 \[
	dep(p) = \{q~|~\exists r \in P: pred(h(r)) = p \land \exists l \in b(r): pred(l) = q\}
\]
Intuitively, the dependencies of a predicate $p$ are all predicates of which all ground instances must be known in ordertocompute all ground instances of $p$.
A set $S$ of predicates $p_1,\ldots,p_n$ is a splitting set of $P$ if the following holds. 
\[
	\forall p:  p \in S \Rightarrow dep(p) \in S
\]
A non-ground splitting set $S_{ng}$ is sematically equivalent to the ground splitting set $S_{grnd}$ one gets by taking all ground instances of all predicates in $S_{ng}$ from the ground program $grnd(P)$.
\end{definition}

\begin{example}[Partial evaluation using splitting sets]
\label{ex:prelims-nonstrat-splitting-sets}
Given program $P_{col}$ from Listing~\ref{lst:prelims-3col-var} in Example~\ref{ex:prelims-nonstrat}, let $S$ be the following (non-ground) splitting set:
\begin{align*}
	S = \{&coloring\_vertex/1,~coloring\_edge/2,~vertex/1,~exclude\_vertex/1, \\
		  &edge/2,~exclude\_edge/2\}
\end{align*}
Using $S$, we can split $P_{col}$ into bottom $B_S(P_{col})$, which is shown in Listing~\ref{lst:prelims-3col-var-bot}, and top $T_S(P_{col})$ in Listing~\ref{lst:prelims-3col-var-top}.
\begin{lstlisting}[style=asp-code, label={lst:prelims-3col-var-bot}, caption={The bottom part of $P_{col}$}]
vertex(a). vertex(b). vertex(c). vertex(d).
edge(a, b). edge(a, c). edge(a, d).
edge(b, c). edge(b, d). edge(c, d).
edge(X, Y) :- edge(Y, X).
	
exclude_vertex(d).
exclude_edge(V1, V2) :- edge(V1, V2), exclude_vertex(V1).
exclude_edge(V1, V2) :- exclude_edge(V2, V1).
	
coloring_vertex(V) :- vertex(V), not exclude_vertex(V).
coloring_edge(V1, V2) :- 
	edge(V1, V2), not exclude_edge(V1, V2).
\end{lstlisting}
Looking at $B_S(P_{col})$, we can observe that this sub-program of $P_{col}$ is now stratified, and can therefore be evaluated using the straight-forward computation employed in Example~\ref{ex:prelims-strat-eval}. We arrive at the following model for $B_S(P_{col})$:
\begin{align*}
	LM(B_S(P_{col})) = \{&coloring\_vertex(b),~exclude\_vertex(d),~edge(b, d), \\
						 &edge(a, b),~edge(c, d),~edge(c, b),~coloring\_edge(b, c),\\
						 &coloring\_edge(a, c),~coloring\_edge(b, a),~edge(a, d),\\
						 &coloring\_edge(c, a),~vertex(c),~	vertex(a),~edge(d, b), \\
						 &exclude\_edge(d, b),~exclude\_edge(c, d),~exclude\_edge(a, d),\\
						 &coloring\_vertex(c),~exclude\_edge(b, d),~coloring\_vertex(a),\\
						 &edge(a, c),~edge(b, c),~edge(b, a),~edge(d, c),coloring\_edge(a, b)\\
						 &coloring\_edge(c, b),~vertex(d),~exclude\_edge(d, a),~vertex(b)\\
						 &edge(c, a),~exclude\_edge(d, c),~edge(d, a)\}
\end{align*}		
\begin{lstlisting}[style=asp-code, label={lst:prelims-3col-var-top}, caption={The top part of $P_{col}$}]
% Guess colors
red(V) :- coloring_vertex(V), not green(V), not blue(V).
green(V) :- coloring_vertex(V), not red(V), not blue(V).
blue(V) :- coloring_vertex(V), not red(V), not green(V).
	
% Filter invalid guesses
:- coloring_vertex(V1), coloring_vertex(V2), 
	coloring_edge(V1, V2), red(V1), red(V2).
:- coloring_vertex(V1), coloring_vertex(V2), 
	coloring_edge(V1, V2), green(V1), green(V2).
:- coloring_vertex(V1), coloring_vertex(V2), 
	coloring_edge(V1, V2), blue(V1), blue(V2).
\end{lstlisting}	
In order to compute the answer sets of the complete program, by the splitting set theorem, we only have to compute the answer sets of $T_S(P_{col}) \cup pr(LM(B_S(P_{col})))$. A simple (but computationally expensive) way to do this would be to perform an exhaustive search over all combinations of ground instances of the rules from lines 2 to 4 and drop all model candidates where any of the constraints fire.
We finally get the following answer sets (filtered for predicates $red/1$, $green/1$ and $blue/1$):
\begin{align*}
	A_1 &= \{blue(c),~green(b),~red(a)\}\\
	A_2 &= \{blue(b),~green(c),~red(a)\}\\
	A_3 &= \{blue(b),~green(a),~red(c)\}\\
	A_4 &= \{blue(c),~green(a),~red(b)\}\\
	A_5 &= \{blue(a),~green(b),~red(c)\}\\
	A_6 &= \{blue(a),~green(c),~red(b)\}
\end{align*}	
\end{example}	

Expanding on Example~\ref{ex:prelims-nonstrat-splitting-sets}, it is clear that a stratifiable bottom with respect to some splitting set always exists - every program has at least the empty set as a trivial splitting set. We call the maximal stratifiable sub-program that only depends on facts (i.e. is a bottom w.r.t some splitting set) \gls{cbp}, see Definition~\ref{def:prelims-asp-semantics-cbp}.

\begin{definition}[Common Base Program, adapted from~\cite{partial-eval}]
\label{def:prelims-asp-semantics-cbp}
Given a splitting set $S$ of program $P$, the bottom $B_S(P)$ is called \emph{common base program}, i.e. $CBP(P)$ if it is stratified and maximal in the sense that adding any further rule to $B_S(P)$ would destroy the property of $B_S(P)$ of being stratified.
\end{definition}

In Alpha, solving programs is a two-step process, where first the model of the \gls{cbp} is computed, and then the remaining program is solved using an algorithm based on \gls{cdnl}~\cite{lazy-cdnl}. Section~\ref{subsec:prelims-lazygrounding-alpha-cdnl} gives a highlevel overview of Alpha's ground-and-solve component. TODO some general stuff about cdnl, reference to clingo as a typical cdnl-solver, "in the following we briefly introduce Alpha's superfacny variation on it"

\subsection{CDNL-based solving in a lazy-grounding Answer Set Solver}
\label{subsec:prelims-lazygrounding-alpha-cdnl}

\begin{definition}[Alpha-Assignment, Nogood~\cite{lazy-cdnl}]
An \emph{Alpha-Assignment}, in the following just \emph{assignment} is a sequence $A = \{sl1,\ldots,sl_n\}$ of literals $l_1\ldots,l_n$ preceded by a \emph{sign} $s \in \{T, M, F\}$. Intuitively, a signed literal $sl_i$ assigns the truth value $s$ to literal $l$. Possible truth values are \emph{true} ($T$), \emph{false} ($F$) and \emph{must-be-true} ($M$). Must-be-true is used as truth value for literals that are deemed by the solver to necessarily be true (e.g. because of a constraint precluding any other truth value), but there is no known firing rule (yet) which would allow assigning $T$. The \emph{boolean projection} $A^{\mathcal{B}}$ of an assignment $A$ is defined as: 
\[
	A^{\mathcal{B}} = \{ Ta~|~Ta \in A \lor Ma \in A\} \cup \{ Fa~|~Fa \in A\}
\]
\\
A \emph{nogood}, in the variant used by Alpha, is a set of signed literals intuitively characterizing a set of literals that may not occur in an assignment with the given truth values:
\[
	ng = \{ sl_1,\ldots,sl_n \}, s \in \{T, F\}
\]
An assignment $A$ \emph{satisfies} a nogood $ng$ if $ng \nsubseteq A^{\mathcal{B}}$. Furthermore, an assignment $A$ is a \emph{solution} to a set $\Delta$ of nogoods if $\{a~|~Ta \in A^{\mathcal{B}}\} \cap \{a~|~Fa \in A^{\mathcal{B}}\} = \emptyset$,  $\{a~|~Ta \in A^{\mathcal{B}}\} \cup \{a~|~Fa \in A^{\mathcal{B}}\} = A^{\mathcal{B}}$ and $\forall ng in \Delta: ng \nsubseteq A^{\mathcal{B}}$.
\end{definition}

\begin{definition}[Nogood representation of rules~\cite{lazy-cdnl}]
\end{definition}	



% \begin{definition}[Unification]
% \label{def:prelims-asp-semantics-unification}
% Let $l_1$, $l_2$ be literals. Then a substitution $\sigma$ is a \emph{unifier} of $l_1$ and $l2$ iff $l_{1}\sigma$ = $l_{2}\sigma$. Two literals for which a unifier exists are said to be \emph{unifiable}. We use the notation $l_1 \uplus l_2$ to express that $l_1$ and $l_2$ are unifiable.
% \end{definition}

% \begin{definition}[Defining rules]
% \label{def:prelims-asp-semantics}
% Given an \gls{asp} program $P$ and literal $l$ of form $a$ or $\NOT\ a$ with atom $a$, the set $\mathit{def}(l)$ of \emph{defining rules} of $l$ is defined as
% \[
% 	\mathit{def}(l) = \{ r\ |\ r \in P \land h(r) \uplus a \}
% \]
% i.e. all rules in $P$ whose head is unifiable with $a$.
% \end{definition}

% \begin{definition}[Stratification, adapted from~\cite{stratification}]
% \label{def:prelims-asp-semantics-stratification}
% Given a (non-ground) \gls{asp} program $P$, a stratification is a partition $S$ of $P$ into sub-programs called \emph{strata} $(P_0,\ldots,P_1)$ such that
% \begin{itemize}
% 	\item $\cup^{n}_{i = 0} P_i = P$, i.e. $S$ is total,
% 	\item $\forall i \geq 0: \forall r \in P_i: \forall l \in b^{+}(r): \mathit{def}(l) \subseteq \cup^{i}_{j = 0} P_j$, i. e. for every positive body literal $l$ of every rule $r$, it holds that all rules defining $l$ reside in a stratum with lower or equal index to the stratum $r$ resides in, and
% 	\item $\forall i \geq 0: \forall r \in P_i: \forall l \in b^{-}(r): \mathit{def}(l) \subseteq \cup^{i - 1}_{j = 0} P_j$, i. e. for every negative body literal $l$ of every rule $r$, it holds that all rules defining $l$ reside in a stratum with strictly lower index than the stratum $r$ resides in.
% \end{itemize}
% A program is called \emph{stratified} iff a stratification exists for it.
% \end{definition}

% \begin{definition}[Stratified Evaluation, adapted from~\cite{asp-primer} and~\cite{stratification}]
% \label{def:prelims-asp-semantics-stratified-eval}
% Let $P$ be an \gls{asp} program, $S = (P_0,\ldots,P_n)$ a stratification of $P$ and $T_{P_i}$ with $0 \leq i \leq n$ the immediate consequence operator for sub-program $P_i \in S$ respectively. Then the least model $\mathit{LM}(P)$ of $P$ is defined as follows.
% The sequence $\langle M_{P_i} \rangle,\ 0 \leq i \leq n$ with $M_{P_0} = \mathit{lfp}(T_{P_0})$ and $M_{P_i} = \mathit{lfp}(T_{P_i \cup\ M_{S_{i-1}}})$ for all $1 \leq i \leq n$ defines the least model for each stratum. The least model $LM(P)$ of program $P$ is then the least model of the highest stratum $M_{P_n}$, i.e. the end of the sequence $\langle M_{P_i} \rangle$.
% \end{definition}

% \begin{definition}[Dependencies]
% \label{def:prelims-asp-semantics-dependencies}
% Let $P$ be an \gls{asp} program and $r \in P$ a rule contained in $P$. a rule $d$ is a \emph{positive dependency} of $r$ , i.e. $ r \DEP{+} d$ iff one the following holds:
% \begin{itemize}
% 	\item $\exists l \in b^{+}(r): d \in \mathit{def}(l) $, i.e. $d$ is a defining rule for some positive body literalof $r$, or
% 	\item $\exists d_1 \in P: r \DEP{+} d_1 \land d_1 \DEP{+} d$, i.e. there is some positive dependency $d_1$ of $r$ of which $d$ is a (transitive) positive dependency.
% \end{itemize}
% \emph{Negative dependencies} are defined in the same way, i.e. a rule $d$ is a negative dependency of $r$, $r \DEP{-} d$ iff
% \begin{itemize}
% 	\item $\exists l \in b^{-}(r): d \in \mathit{def}(l)$, i.e. $d$ is a defining rule for some negative body literalof $r$, or
% 	\item $\exists d_1 \in P: r \DEP{-} d_1 \land d_1 \DEP{-} d$, i.e. there is some negative dependency $d_1$ of $r$ of which $d$ is a (transitive) negative dependency.
% \end{itemize}
% Any positive or negative dependency $d$ of $r$ is a \emph{dependency} of $r$, i.e. $r \DEP{} d$.
% We denote the set of dependencies of a rule as $D(r) = \{ d\ |\ r \DEP{} d\}$ and positive and negative dependencies as $D^{+}(r) = \{ d\ |\ r \DEP{+} d\}$ and $D^{-}(r) = \{ d\ |\ r \DEP{-} d\}$ respectively. Any non-transitive dependency of a rule is called a \emph{direct dependency}.
% \end{definition}

% \begin{definition}[Dependency Graph]
% \label{def:prelims-asp-semantics-depgraph}
% Let $P$ be an \gls{asp} program. Then the \emph{dependency graph}  $\mathit{DG}_P = (R, D)$ is a directed graph with vertex set $R$, which has one element for each rule in $P$, and (dependency-)edge set $D$ such that
% \begin{align*}
% 	D = &\{ (r_1, r_2, +)\ |\ r_1,\ r_2 \in P \land r_2\ \mathit{is\ direct\ positive\ dependency\ of}\ r_1 \}\\ &\cup
% \{ (r_1, r_2, -)\ |\ r_1,\ r_2 \in P \land r_2\ \mathit{is\ direct\ negative\ dependency\ of}\ r_1 \}
% \end{align*}
% Edges are represented as 3-tuples where the first two values represent target and destination vertices and the third value indicates the "polarity", i. e. positive ("+") or negative ("-"), of the dependency.
% \end{definition}

% \begin{definition}[Component Graph]
% \label{def:prelims-asp-semantics-compgraph}
% The component graph $\mathit{CG}_P = (C, D)$ of a program $P$ is defined as the "condensed" dependency graph, i. e. vertices of $\mathit{CG}_P$ represent strongly connected components of $\mathit{DG}_P$. Each vertex of $\mathit{CG}_P$ is labelled "$+$" if the respective strongly connected component is connected only by positive edges, or "$-$" if there is a negative edge in the component. Edges of $\mathit{CG}_P$ are those edges of $\mathit{DG}_P$ that connect vertices from different strongly connected components where douuble edges resulting from multiple rule-level dependencies of same polarity between components are condensed into single edges.
% \end{definition}

% \begin{definition}[Splitting Set, adapted from~\cite{splitting-sets}]
% \label{def:prelims-asp-semantics-splitting-set}
% Given a program $P$, a set of atoms $U$ is a \emph{splitting set} of $P$ if for every rule $r$, where $h(r) \in U$, also the atoms corresponding to all body literals of $r$ are in $U$. The set of rules corresponding to $U$, i.e. the rules defining the atoms in $U$, is called \emph{bottom} of $P$ with respect to $U$, denoted as $B_U(P)$. Consequently, $P \setminus B_U(P)$ is called \emph{top} of $P$, which is denoted as $T_U(P)$.
% \end{definition}



% Intuitively, a set of rule heads is a splitting set if for every rule head in the set, all rule heads on which it depends are in the set as well. The importance of the notion of a splitting set lies in the fact that answer set computation can be split up using splitting sets: Given a splitting set, we can first calculate all answer sets of the bottom, and then solve the top with respect to each of those answer sets~\cite{splitting-sets}.\\

% Alpha's evaluation logic makes use of this by evaluating first the maximum stratified bottom (\emph{common base program}, see Definition~\ref{def:prelims-asp-semantics-cbp}) using the simplified bottom-up algorithm outlined in Algorithm \ref{alg:cbp-eval} and then only using the - computationally more complex - \gls{cdnl}-based algorithm for the top part.

\begin{algorithm}[!h]
\SetAlgoLined
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\SetKwRepeat{Do}{do}{while}
\Input{Stratification $S$}
\Input{Program $P$}
\Output{partially evaluated program $P_{eval}$}
Facts $F$ = \emph{facts($P$)};\\
$n~\leftarrow~(\mid S \mid~-~1)$;\\
\ForEach{$i~$\emph{\textbf{in}} $0 \ldots n$}{
	Program $grnd(P_{S_i})$ = \emph{ground($P_{S_i}$)};\\
	Facts $F_{old} = \emptyset$;\\
	\Do{$F_{old} \neq F$}{
		$F_{old} = F$;\\ 
		$F \leftarrow pr(T_{grnd(P_{S_i})}(F))$;\\
	}
	$P \leftarrow P \backslash P_{S_i}$;\\
}
\textbf{return} $P_{eval} = P~\cup~F$;\\
\caption{Procedure \emph{evaluateCommonBaseProgram}}\label{alg:cbp-eval}
\end{algorithm}

\section{Answer Set Programming}

When speaking of \gls{asp}, we nowadays mostly refer to the language specfied by the ASP-Core2 standard~\cite{asp-core2}. It uses the \emph{stable model semantics} by Gelfond and Lifschitz~\cite{stable-models} as a formal basis and enhances it with support for advanced concepts such as disjunctive programs, aggregate literals and weak constraints. This chapter describes the input language supported by the Alpha solver, which will serve as the basis on which we will define the Evolog language.

\subsection{Syntax}
\label{subsec:prelims-asp-syntax}

\begin{definition}[Integer numeral]
\label{def:prelims-asp-syntax-int}
An \emph{integer numeral} in the context of an \gls{asp} program is a string matching the regular expression:
\begin{lstlisting}[style=code]
(-)?[0-9]+
\end{lstlisting}
The set of all valid integer numerals is denoted as $\INTs$.
\end{definition}

\begin{definition}[Identifier]
\label{def:prelims-asp-syntax-id}
An \emph{identifier} in the context of an \gls{asp} program is a string matching the regular expression:
\begin{lstlisting}[style=code]
[a-z][a-zA-Z0-9\_]*
\end{lstlisting}
The set of all valid identifiers is denoted as $\IDs$.
\end{definition}

\begin{definition}[Variable Name]
\label{def:prelims-asp-syntax-var}
A \emph{variable name} in the context of an \gls{asp} program is a string matching the regular expression:
\begin{lstlisting}[style=code]
[A-Z][a-zA-Z0-9\_]*
\end{lstlisting}
The set of all valid variable names is denoted as $\VARs$.
\end{definition}

\begin{definition}[Term]
\label{def:prelims-asp-syntax-term}
A \emph{term} is inductively defined as follows:
\begin{itemize}
	\item Any \emph{constant} $c \in (\INTs \cup \IDs)$ is a term.
	\item Any \emph{variable} $v \in \VARs$ is a term.
	\item Given terms $t_1, t_2$, any \emph{artihmetic expression} $t_1 \oplus t_2$ with $\oplus \in \{+, - , *, /, **\}$ is a term.
	\item Given terms $t_1, t_2$, any \emph{interval expression} $t_1 \ldots t_2$ is a term.
	\item For function symbol $f \in \IDs$ and argument terms $t_1, \ldots, t_n$, the \emph{functional expression} $f(t_1, \ldots, t_n)$ is a term.
\end{itemize}
\end{definition}

\begin{definition}[Subterms]
\label{def:prelims-asp-syntax-subterms}
Given a term $t$, the set of \emph{subterms} of $t$, $st(t)$, is defined as follows:
\begin{itemize}
	\item If $t$ is a \emph{constant} or \emph{variable}, $st(t) = \{t\}$.
	\item If $t$ is an \emph{arithmetic expression} $t_1 \oplus t_2$, $st(t) = st(t_1) \cup st(t_2)$.
	\item If $t$ is an \emph{interval expression} $t_1 \ldots t_2$, $st(t) = st(t_1) \cup st(t_2)$.
	\item If $t$ is a \emph{functional expression} with argument terms $t_1, \ldots, t_n$, $st(t) = st(t_1) \cup \ldots \cup st(t_n)$.
\end{itemize}
A term is called \emph{ground} if it is variable-free, i.e. none of its subterms is a variable.
\end{definition}

\begin{definition}[Basic Atom]
\label{def:prelims-asp-syntax-atom}
Given a predicate symbol $p \in \IDs$ and argument terms $t_1,\ldots,t_n$, the expression
\[
	p(t_1,\ldots,t_n)
\]
is called a \emph{atom}. An atom is ground if all of its argument terms are ground. A ground atom with predicate $p$ is called an \emph{instance} of $p$.
\end{definition}

\begin{definition}[Comparison Atom]
\label{def:prelims-asp-syntax-cmp-atom}
Given terms $t_1$ and $t_2$ and comparison operator $\odot$ where $\odot \in \{ <, \leq, =, \geq, >, \neq \}$, the expression
\[
	t_1 \odot t_2
\]
is called a \emph{comparison atom}. Syntactically, a comparison atom is a regular atom where the predicate symbol (i.e. comparison operator) is written in infix- rather than prefix-notation.
\end{definition}

\begin{definition}[External Atom]
\label{def:prelims-asp-syntax-ext-atom}
Given an \emph{external predicate name} $\mathit{ext}$, \emph{input terms} $t_1,\ldots,t_n$ and \emph{output terms} $t_{n+1},\ldots,t_m$, the expression
\[
	@\mathit{ext}[t_1,\ldots,t_n](t_{n+1},\ldots,t_m)
\]
is called an \emph{external atom}. Syntacticaly, external atoms are regular atoms where $@\mathit{ext}$ is the predicate symbol and $t_1,\ldots,t_m$ are argument terms.
\end{definition}

\begin{definition}[Literal]
\label{def:prelims-asp-syntax-literal}
A literal in \gls{asp} is an atom $a$ or ("default"-)negated atom $\NOT\ a$. Literals wrapping comparison- or external atoms are called \emph{fixed interpretation literals}.
\end{definition}

\begin{definition}[Rule, Program]
\label{def:prelims-asp-syntax-rule}
A \emph{rule} is an expression of form
\[
	a_H \leftarrow b_1,\ldots,b_n.
\]
for $n \geq 0$, where the \emph{rule head} $a_H$ is an atom and the \emph{rule body} $b_1,\ldots,b_n$ is a set of literals. An \gls{asp} \emph{program} is a set of rules. A rule with an empty body is called a \emph{fact}. A rule is \emph{ground} if both its head atom and all of its body literals are ground. By the same reasoning, a program is ground if all of its rules are ground.\\
Given a rule $r$, he refer to the head of $r$ as $h(r)$ and the body of $r$ as $b(r)$. Furthermore, $b^+(r)$ is used to reference the set of \emph{positive body literals} of $r$, while $b^-(r)$ references the \emph{negative body literals}. 
\end{definition}

\begin{definition}[Constraint]
\label{def:prelims-asp-syntax-constraint}
A \emph{constraint} is a special form of rule, written as a rule with an empty head, i.e.
\[
	\leftarrow b_1,\ldots,b_n.
\]
It is syntactic sugar for
\[
	q \leftarrow b_1,\ldots,b_n, \NOT\ q.
\]
where $q$ is a propositional constant not occurring in any other rule in the program.
\end{definition}

\subsection{Semantics}
\label{subsec:prelims-asp-semantics}

\begin{definition}[Herbrand Universe]
\label{def:prelims-asp-semantics-hu}
The Herbrand Universe $HU_P$ of a Program $P$ is the set of all valid terms that can be constructed with respect to Definitions~\ref{def:prelims-asp-syntax-int},~\ref{def:prelims-asp-syntax-id} and \ref{def:prelims-asp-syntax-term}.
Note that most papers use stricter definitions of the Herbrand Universe where $HU_P$ consists only of terms constructible from constants occurring in $P$. The broader definition used here is chosen for ease of definition with respect to some of the extensions introduced in Section~\ref{sec:evolog-actions}.
\end{definition}

\begin{definition}[Herbrand Base]
\label{def:prelims-asp-semantics-hb}
The Herbrand Base $HB_P$ of a Program $P$ is the set of all ground atoms that can be constructed from the Herbrand Universe $HU_P$ according to definition~\ref{def:prelims-asp-syntax-atom}. 
\end{definition}

\begin{definition}[Herbrand Interpretation]
\label{def:prelims-asp-semantics-herbrand-interpretation}
A Herbrand Interpretation is a special form of first order interpretation where the domain of the interpretation is a Herbrand Universe and terms are the interpretation of a term is the term itself, i.e. the corresponding element of $HU_P$. Intuitively, Herbrand Interpretations constitute listings of atoms that are true in a given program. Since the domain of a Herbrand Interpretation is always the Herbrand Universe $HU_P$, we only need to give a predicate interpretation for the predicates occurring in a program $P$ in oder to fully specify a Herbrand Interpretation. We can therefore denote Herbrand Interpretations as sets of atoms $I \subseteq HB_P$.
\end{definition}

\subsubsection{Grounding}
\label{subsubsec:prelims-grounding}
Given a program $P$ containing variables, \emph{grounding} refers to the process of converting $P$ into a semantically equivalent propositional, i.e. variable-free, program.

\begin{definition}[Substitution, adapted from~\cite{lazy-cdnl}]
\label{def:prelims-asp-semantics-substitution}
A substitution $\sigma: \VARs \mapsto (\IDs \cup \INTs)$ is a mapping from variables to constants. For a atom $a$, applying a a substitution results in a substituted atom $a\sigma$ in which variables are replaced according to $\sigma$. Substitutions are applied to rules  by applying them to every individual atom or literal within the rule. By the same mechanism, we can apply substitutions to programs by applying the to all rules.
\end{definition}

\begin{definition}[Grounding]
\label{def:prelims-asp-semantics-grounding}
Given a rule $r$, the \emph{grounding} of $r$, $\mathit{grnd}(r)$, is a set of substitutions $S$, such that the set of ground rules resulting from applying the substitutions in $S$ is semantically equivalent to $r$. In a slight abuse of terminology, \emph{grounding} in this work also refers to the set of ground rules resulting from applying $S$ as well as the process of finding said set.
\end{definition}

\subsubsection{Stable Model Semantics}
\label{subsubsec:prelims-asp-semantics-stable-models}

\begin{definition}[Fixed interpretation literals]
Fixed interpretation literals, i.e. comparison- and external literals, respectively, are interpreted by means of a program-independent oracle function $f_O : H_{U}(P)^{*} \mapsto \{ \top, \bot \}$, i.e. a fixed interpretation literal with argument terms $t_1,\ldots,t_n$ has the same truth value under all interpretations.
\end{definition}

\begin{definition}[Truth of Atoms and Literals]
\label{def:prelims-asp-semantics-truth}
A positive ground literal $l$ with atom $a$ is true w.r.t. a Herbrand Interpretation $I$, i.e. $I \models l$ if
\begin{itemize}
	\item $a$ is a basic atom contained in $I$, i.e. $a \in I$,
	\item $a$ is a fixed interpretation literal with terms $t_1,\ldots,t_n$ and $f_O(t_1,\ldots,t_n) = \top$.
\end{itemize} 
For a negative ground literal $\NOT\ a$, the reverse holds, i.e. $I \models \NOT\ a$ if
\begin{itemize}
	\item $a$ is a basic atom not contained in $I$, i.e. $a \notin I$,
	\item $a$ is a fixed interpretation literal with terms $t_1,\ldots,t_n$ and $f_O(t_1,\ldots,t_n) = \bot$.
\end{itemize} 
A set of literals $L$ is true w.r.t. an interpretation $I$ if $I \models l$ holds for every literal $l \in L$. 
\end{definition}

\begin{definition}[Positive Logic Program]
\label{def:prelims-asp-semantics-positive-program}
A \emph{positive} logic program is a program according to Definition \ref{def:prelims-asp-syntax-rule}, where all rule bodies are positive, i.e. no rule body contains a negated atom.
\end{definition}

\begin{definition}[Immediate Consequence Operator, adapted from~\cite{asp-primer}]
\label{def:prelims-asp-semantics-immediate-consequence}
Given a Herbrand Interpretation $I$ and a ground positive logic program $P$, the immediate  consequence operator $T_P(I)$ defines a monotonic function $T_P: 2^{HB_P} \mapsto 2^{HB_P}$ such that
\[
	T_P(I) = \{h(r)\ |\ r \in P \land I \models b(r)\}
\]
i.e. the result set of applying $T_P$ with a Herbrand Interpretation $I$ contains the heads of all rules whose body is true under $I$.
\end{definition}

\begin{definition}[Least Model of positive logic programs]
\label{def:prelims-asp-semantics-least-model}
The least model $LM(P)$ of a (ground) positive logic program $P$ is the least fixpoint of the $T_P$ operator  of $P$, i.e. the set toward which the sequence $\langle T^{i}_{P} \rangle$, with $i \geq 0$, $T^{0}_P = \emptyset$ and $T^{i}_P = T_P(T^{i-1}_P)$ for $i \geq 1$, converges. The existence of said fixpoint and its characterisation as limit of $\langle T^{i}_{P} \rangle$ follow from the fixpoint theorems of Knaster, Tarski and Kleene, respectively.
\end{definition}

\begin{definition}[Gelfond-Lifschitz Reduct, adapted from~\cite{stable-models} and~\cite{asp-primer}]
\label{def:prelims-asp-semantics-gl-reduct}
Given a ground \gls{asp} program $P$ and a Herbrand Interpretation $I$, the \emph{Gelfond-Lifschitz-Reduct} ("GL-reduct") $P^{I}$of $P$ with respect to $I$ is the program obtained by:
\begin{itemize}
	\item removing from $P$ all rules $r$ that are "blocked", i.e. $I \not\models l$ for some literal $l \in b^{-}(r)$ 
	\item and removing the negative body of all other rules.
\end{itemize}
Note that $P^{I}$ is a positive logic program.
\end{definition}

\begin{definition}[Answer Set~\cite{stable-models}~\cite{asp-primer}]
\label{def:prelims-asp-semantics-answer-set}
A Herbrand Interpretation $I$ of an \gls{asp} program $P$ is an \emph{answer set} or \emph{stable model} of $P$ iff it is the least model $LM(P^I)$ of the GL-reduct $P^I$ of $P$.
\end{definition}

\section{Lazy-Grounding ASP Solving}

\subsection{Two-phased ASP solving}
In traditional \gls{asp} solving systems such as SModels~\cite{smodels}, DLV~\cite{dlv} or Clingo~\cite{clingo}, grounding an input program and solving the resulting propositional program are distinct sequential steps in the overall solving process. Consequently, in order to obtain answer sets of a program, one has to calculate a grounding for the entire program first, and can only then start the actual solver. Since the grounding of an arbitrary program may be exponentially larger than the nonground program or, in some extreme cases, not even finite, calculating a full grounding is often not feasible, especially for programs where only very few ground rules can actually fire. Lazy-grounding systems like Alpha try to alleviate this by interleaving the grounding- and solving steps and ideally ground only as much of the input programs as is necessary to find all answer sets.

\subsection{Conceptual solving workflow in Alpha}

The formal basis of lazy-grounding architectures lies in the notion of a \emph{computation sequence}, i.e. a set of rules firing in a given order in order to get to an interpretation that is an answer set. Definition \ref{def:prelims-asp-semantics-compseq} formally introduces computation sequences.

\begin{definition}[Computation Sequence, adapted from ~\cite{lazy-cdnl} and~\cite{asperix-fw-chain}]
\label{def:prelims-asp-semantics-compseq}
Let $P$ be an \gls{asp} program and $S = (A_0,\ldots,A_{\infty})$ a sequence of assignments, i.e. herbrand interpretations denoted by a set of atoms assumed to be true, then $S$ is called a \emph{computation sequence} iff
\begin{itemize}
	\item $A_0 = \emptyset$
	\item $\forall i \geq 1: A_i \subseteq T_P(A_{i - 1})$, i.e. every $A_i$ is a consequence of its predecessor in the sequence,
	\item $\forall i \geq 1: A_{i - 1} \subseteq A_{i}$, i.e. S is monotonic,
	\item $A_{\infty} = \cup^{\infty}_{i = 0} A_i = T_P(A_{\infty})$, i.e. $S$ converges toward a fixpoint and
	\item $\forall i \geq 1: \forall a \ \in A_i \setminus A_{i - 1}, \exists r \in P: h(r) = a \land \forall j \geq i - 1: A_j \models a$, i.e. applicability of rules is persistent.
\end{itemize}
$A_{\infty}$ is an answer set of $P$ iff $S$ is a computation sequence. Note that there may exist an arbitrary number of computation sequences leading to the same answer set.
\end{definition}

Obviously, computation sequences can be easily found by simple iterative application of the $T_P$ operator for programs that do not use negation in rules. However, since in general once negation comes into play, solvers may have to retract assignments of atoms ("backtrack"), over the course of the solving process. \todo{Example of mutually blocking rules!} Lazy-grounding solvers suffer from a performance penalty compared to two-phased systems in that respect. This penalty results from algorithms based on \gls{cdnl}~\cite{clasp-cdnl} achieving higher performance since conflicts occur faster and more nogoods can be learned from them with a full grounding available. A key challenge in designing lazy-grounding systems is therefore identifying classes of programs as well as groups of rules within programs that can be evaluated using simplified deterministic algorithms in order to minimize the number of potential backtracks.

\subsubsection{Structural Dependency Analysis and Stratified Evaluation}

\todo{Since we're talking about nonground stratification, should we define a nonground $T_P$ operator! Just simply say we add the rules where all defining rules have already fired in each step}

\begin{definition}[Unification]
\label{def:prelims-asp-semantics-unification}
Let $l_1$, $l_2$ be literals. Then a substitution $\sigma$ is a \emph{unifier} of $l_1$ and $l2$ iff $l_{1}\sigma$ = $l_{2}\sigma$. Two literals for which a unifier exists are said to be \emph{unifiable}. We use the notation $l_1 \uplus l_2$ to express that $l_1$ and $l_2$ are unifiable.
\end{definition}

\begin{definition}[Defining rules]
\label{def:prelims-asp-semantics}
Given an \gls{asp} program $P$ and literal $l$ of form $a$ or $\NOT\ a$ with atom $a$, the set $\mathit{def}(l)$ of \emph{defining rules} of $l$ is defined as
\[
	\mathit{def}(l) = \{ r\ |\ r \in P \land h(r) \uplus a \}
\]
i.e. all rules in $P$ whose head is unifiable with $a$.
\end{definition}

\begin{definition}[Stratification, adapted from~\cite{stratification}]
\label{def:prelims-asp-semantics-stratification}
Given a (non-ground) \gls{asp} program $P$, a stratification is a partition $S$ of $P$ into sub-programs called \emph{strata} $(P_0,\ldots,P_1)$ such that
\begin{itemize}
	\item $\cup^{n}_{i = 0} P_i = P$, i.e. $S$ is total,
	\item $\forall i \geq 0: \forall r \in P_i: \forall l \in b^{+}(r): \mathit{def}(l) \subseteq \cup^{i}_{j = 0} P_j$, i. e. for every positive body literal $l$ of every rule $r$, it holds that all rules defining $l$ reside in a stratum with lower or equal index to the stratum $r$ resides in, and
	\item $\forall i \geq 0: \forall r \in P_i: \forall l \in b^{-}(r): \mathit{def}(l) \subseteq \cup^{i - 1}_{j = 0} P_j$, i. e. for every negative body literal $l$ of every rule $r$, it holds that all rules defining $l$ reside in a stratum with strictly lower index than the stratum $r$ resides in.
\end{itemize}
A program is called \emph{stratified} iff a stratification exists for it.
\end{definition}

\begin{definition}[Stratified Evaluation, adapted from~\cite{asp-primer} and~\cite{stratification}]
\label{def:prelims-asp-semantics-stratified-eval}
Let $P$ be an \gls{asp} program, $S = (P_0,\ldots,P_n)$ a stratification of $P$ and $T_{P_i}$ with $0 \leq i \leq n$ the immediate consequence operator for sub-program $P_i \in S$ respectively. Then the least model $\mathit{LM}(P)$ of $P$ is defined as follows.
The sequence $\langle M_{P_i} \rangle,\ 0 \leq i \leq n$ with $M_{P_0} = \mathit{lfp}(T_{P_0})$ and $M_{P_i} = \mathit{lfp}(T_{P_i \cup\ M_{S_{i-1}}})$ for all $1 \leq i \leq n$ defines the least model for each stratum. The least model $LM(P)$ of program $P$ is then the least model of the highest stratum $M_{P_n}$, i.e. the end of the sequence $\langle M_{P_i} \rangle$.
\end{definition}

\begin{definition}[Dependencies]
\label{def:prelims-asp-semantics-dependencies}
Let $P$ be an \gls{asp} program and $r \in P$ a rule contained in $P$. a rule $d$ is a \emph{positive dependency} of $r$ , i.e. $ r \DEP{+} d$ iff one the following holds:
\begin{itemize}
	\item $\exists l \in b^{+}(r): d \in \mathit{def}(l) $, i.e. $d$ is a defining rule for some positive body literalof $r$, or
	\item $\exists d_1 \in P: r \DEP{+} d_1 \land d_1 \DEP{+} d$, i.e. there is some positive dependency $d_1$ of $r$ of which $d$ is a (transitive) positive dependency.
\end{itemize}
\emph{Negative dependencies} are defined in the same way, i.e. a rule $d$ is a negative dependency of $r$, $r \DEP{-} d$ iff
\begin{itemize}
	\item $\exists l \in b^{-}(r): d \in \mathit{def}(l)$, i.e. $d$ is a defining rule for some negative body literalof $r$, or
	\item $\exists d_1 \in P: r \DEP{-} d_1 \land d_1 \DEP{-} d$, i.e. there is some negative dependency $d_1$ of $r$ of which $d$ is a (transitive) negative dependency.
\end{itemize}
Any positive or negative dependency $d$ of $r$ is a \emph{dependency} of $r$, i.e. $r \DEP{} d$.
We denote the set of dependencies of a rule as $D(r) = \{ d\ |\ r \DEP{} d\}$ and positive and negative dependencies as $D^{+}(r) = \{ d\ |\ r \DEP{+} d\}$ and $D^{-}(r) = \{ d\ |\ r \DEP{-} d\}$ respectively. Any non-transitive dependency of a rule is called a \emph{direct dependency}.
\end{definition}

\begin{definition}[Dependency Graph]
\label{def:prelims-asp-semantics-depgraph}
Let $P$ be an \gls{asp} program. Then the \emph{dependency graph}  $\mathit{DG}_P = (R, D)$ is a directed graph with vertex set $R$, which has one element for each rule in $P$, and (dependency-)edge set $D$ such that
\begin{align*}
	D = &\{ (r_1, r_2, +)\ |\ r_1,\ r_2 \in P \land r_2\ \mathit{is\ direct\ positive\ dependency\ of}\ r_1 \}\\ &\cup
\{ (r_1, r_2, -)\ |\ r_1,\ r_2 \in P \land r_2\ \mathit{is\ direct\ negative\ dependency\ of}\ r_1 \}
\end{align*}
Edges are represented as 3-tuples where the first two values represent target and destination vertices and the third value indicates the "polarity", i. e. positive ("+") or negative ("-"), of the dependency.
\end{definition}

\begin{definition}[Component Graph]
\label{def:prelims-asp-semantics-compgraph}
The component graph $\mathit{CG}_P = (C, D)$ of a program $P$ is defined as the "condensed" dependency graph, i. e. vertices of $\mathit{CG}_P$ represent strongly connected components of $\mathit{DG}_P$. Each vertex of $\mathit{CG}_P$ is labelled "$+$" if the respective strongly connected component is connected only by positive edges, or "$-$" if there is a negative edge in the component. Edges of $\mathit{CG}_P$ are those edges of $\mathit{DG}_P$ that connect vertices from different strongly connected components where douuble edges resulting from multiple rule-level dependencies of same polarity between components are condensed into single edges.
\end{definition}

\begin{definition}[Splitting Set, adapted from~\cite{splitting-sets}]
\label{def:prelims-asp-semantics-splitting-set}
Given a program $P$, a set of atoms $U$ is a \emph{splitting set} of $P$ if for every rule $r$, where $h(r) \in U$, also the atoms corresponding to all body literals of $r$ are in $U$. The set of rules corresponding to $U$, i.e. the rules defining the atoms in $U$, is called \emph{bottom} of $P$ with respect to $U$, denoted as $B_U(P)$. Consequently, $P \setminus B_U(P)$ is called \emph{top} of $P$, which is denoted as $T_U(P)$.
\end{definition}

\begin{definition}[Common Base Program, adapted from~\cite{partial-eval}]
\label{def:prelims-asp-semantics-cbp}
Given a splitting set $S$ of program $P$, the bottom $B_S(P)$ is called \emph{common base program}, i.e. $CBP(P)$ if it is stratified and maximal in the sense that adding any further rule to $B_S(P)$ would destroy the property of $B_S(P)$ of being stratified.
\end{definition}

Intuitively, a set of rule heads is a splitting set if for every rule head in the set, all rule heads on which it depends are in the set as well. The importance of the notion of a splitting set lies in the fact that answer set computation can be split up using splitting sets: Given a splitting set, we can first calculate all answer sets of the bottom, and then solve the top with respect to each of those answer sets~\cite{splitting-sets}.\\

Alpha's evaluation logic makes use of this by evaluating first the maximum stratified bottom (\emph{common base program}, see Definition~\ref{def:prelims-asp-semantics-cbp}) using the simplified bottom-up algorithm outlined in Algorithm \ref{alg:cbp-eval} and then only using the - computationally more complex - \gls{cdnl}-based algorithm for the top part.

\begin{algorithm}[!h]
\SetAlgoLined
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}
\SetKwRepeat{Do}{do}{while}
\Input{Stratification $S$}
\Input{Program $P$}
\Output{partially evaluated program $P_{eval}$}
Facts $F$ = \emph{facts($P$)};\\
$n~\leftarrow~(\mid S \mid~-~1)$;\\
\ForEach{$i~$\emph{\textbf{in}} $0 \ldots n$}{
	Program $grnd(P_{S_i})$ = \emph{ground($P_{S_i}$)};\\
	Facts $F_{old} = \emptyset$;\\
	\Do{$F_{old} \neq F$}{
		$F_{old} = F$;\\ 
		$F \leftarrow pr(T_{grnd(P_{S_i})}(F))$;\\
	}
	$P \leftarrow P \backslash P_{S_i}$;\\
}
\textbf{return} $P_{eval} = P~\cup~F$;\\
\caption{Procedure \emph{evaluateCommonBaseProgram}}\label{alg:cbp-eval}
\end{algorithm}
